<!DOCTYPE html><html lang="en"><head itemscope=""><script type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"insights","name":"Insights"}},{"@type":"ListItem","position":2,"item":{"@id":"ClickHouse","name":"ClickHouse"}},{"@type":"ListItem","position":3,"item":{"@id":"kafka","name":"Kafka"}}]},{"@type":"BlogPosting","@id":"https://double.cloud/blog/posts/2024/09/real-time-analytics-kafka-clickhouse-integration/","url":"https://double.cloud/blog/posts/2024/09/real-time-analytics-kafka-clickhouse-integration/","name":"Clickstream analytics case study. Part I: Kafka → Data Transfer → ClickHouse","headline":"Clickstream analytics case study. Part I: Kafka → Data Transfer → ClickHouse","abstract":"<p>Written By: Igor Mosyagin, Developer Advocate at&nbsp;DoubleCloud</p>","description":"<p>Written By: Igor Mosyagin, Developer Advocate at&nbsp;DoubleCloud</p>","dateCreated":"2024-09-06T00:00:00Z","datePublished":"2024-09-06T00:00:00Z","dateModified":"2024-09-06T00:00:00Z","author":{"@type":"Organization","name":"DoubleCloud","legalName":"DoubleCloud Inc","url":"https://double.cloud/","logo":{"@type":"ImageObject","url":"","width":32,"height":32}},"creator":{"@type":"Organization","name":"DoubleCloud","legalName":"DoubleCloud Inc","url":"https://double.cloud/","logo":{"@type":"ImageObject","url":"","width":32,"height":32}},"publisher":{"@type":"Organization","name":"DoubleCloud","legalName":"DoubleCloud Inc","url":"https://double.cloud/","logo":{"@type":"ImageObject","url":"","width":32,"height":32}},"copyrightHolder":{"@type":"Organization","name":"DoubleCloud","legalName":"DoubleCloud Inc","url":"https://double.cloud/","logo":{"@type":"ImageObject","url":"","width":32,"height":32}},"copyrightYear":2025,"mainEntityOfPage":{"@type":"WebPage","@id":"https://double.cloud/blog/posts/2024/09/real-time-analytics-kafka-clickhouse-integration/"},"inLanguage":{"@type":"Language","name":"English","alternateName":"en"},"keywords":["Insights","ClickHouse","Kafka"],"image":"https://double.cloud/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-small-cover.png","sharedContent":{"@type":"WebPage","headline":"Clickstream analytics case study. Part I: Kafka → Data Transfer → ClickHouse","url":"https://double.cloud/blog/posts/2024/09/real-time-analytics-kafka-clickhouse-integration/","author":{"@type":"Organization","name":"DoubleCloud","legalName":"DoubleCloud Inc","url":"https://double.cloud/","logo":{"@type":"ImageObject","url":"","width":32,"height":32}}},"wordCount":"","articleBody":""}]}</script><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Clickstream analytics case study. Part I: Kafka -&gt; Data Transfer -&gt; ClickHouse | DoubleCloud</title><meta name="description" content="How to set up a real-time analytics pipeline using Kafka and ClickHouse: initial setup and data loading."/><link rel="canonical" href="../real-time-analytics-kafka-clickhouse-integration.html"/><meta itemProp="name" content="Clickstream analytics case study. Part I: Kafka -&gt; Data Transfer -&gt; ClickHouse"/><meta itemProp="description" content="How to set up a real-time analytics pipeline using Kafka and ClickHouse: initial setup and data loading."/><meta itemProp="image" content="https://double.cloud/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-sharing.png"/><meta property="og:type" content="website"/><meta property="og:url" content="https://double.cloud/blog/posts/2024/09/real-time-analytics-kafka-clickhouse-integration/"/><meta property="og:title" content="Clickstream analytics case study. Part I: Kafka -&gt; Data Transfer -&gt; ClickHouse"/><meta property="og:description" content="How to set up a real-time analytics pipeline using Kafka and ClickHouse: initial setup and data loading."/><meta property="og:image" content="https://double.cloud/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-sharing.png"/><meta property="og:locale" content="en"/><meta property="og:site_name" content="DoubleCloud"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Clickstream analytics case study. Part I: Kafka -&gt; Data Transfer -&gt; ClickHouse"/><meta name="twitter:description" content="How to set up a real-time analytics pipeline using Kafka and ClickHouse: initial setup and data loading."/><meta name="twitter:image" content="https://double.cloud/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-sharing.png"/><meta name="robots" content="follow, index"/><meta property="article:published_time" content="2024-09-06T00:00:00Z"/><meta property="article:author" content=""/><meta property="article:tag" content="Insights"/><meta property="article:tag" content="ClickHouse"/><meta property="article:tag" content="Kafka"/><meta name="next-head-count" content="26"/><link rel="icon" href="../../../../../assets/favicon/favicon.ico" sizes="any"/><link type="image/x-icon" rel="shortcut icon" href="../../../../../assets/favicon/favicon.ico"/><link type="image/png" sizes="16x16" rel="icon" href="../../../../../assets/favicon/favicon-16x16.png"/><link type="image/png" sizes="32x32" rel="icon" href="../../../../../assets/favicon/favicon-32x32.png"/><link type="image/png" sizes="120x120" rel="icon" href="../../../../../assets/favicon/favicon-120x120.png"/><link type="image/png" sizes="192x192" rel="icon" href="../../../../../assets/favicon/favicon-192x192.png"/><link type="image/png" sizes="76x76" rel="apple-touch-icon" href="https://double.cloud/assets/favicon/favicon-76x76.png"/><link type="image/png" sizes="152x152" rel="apple-touch-icon" href="../../../../../assets/favicon/favicon-152x152.png"/><link type="image/png" sizes="180x180" rel="apple-touch-icon" href="../../../../../assets/favicon/favicon-180x180.png"/><script id="data-google-tag-manager" nonce="zQcdnLrPwtUu1QPPXR/ORA==" data-nonce="zQcdnLrPwtUu1QPPXR/ORA==">
                // Define dataLayer and the gtag function.
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}

                // Default analytics_storage to 'denied'.
                window.gtag = window.gtag || gtag;

                const hasAnalyticsConsent = window?.localStorage.getItem('hasAnalyticsConsent');
                const consent =  hasAnalyticsConsent === 'true' ? 'granted' : 'denied';

                window.gtag('consent', 'default', {
                    'analytics_storage': consent,
                    'ad_storage': consent,
                    'wait_for_update': hasAnalyticsConsent === 'true' ? 0 : Infinity,
                });

                dataLayer.push({
                    'event': 'default_consent'
                });

                (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                'https://www.googletagmanager.com/gtm.js?id='+i+dl;var n=d.querySelector('[nonce]');
                n&&j.setAttribute('nonce',n.nonce||n.getAttribute('nonce'));f.parentNode.insertBefore(j,f);
                })(window,document,'script','dataLayer','GTM-5M39N8J');
            </script><script nonce="zQcdnLrPwtUu1QPPXR/ORA==">window.__webpack_nonce__ = "zQcdnLrPwtUu1QPPXR/ORA=="</script><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="preconnect" href="https://snap.licdn.com"/><link rel="preconnect" href="https://www.google.com"/><link nonce="zQcdnLrPwtUu1QPPXR/ORA==" rel="preload" href="../../../../../_next/static/css/a4c87e381fd61058.css" as="style"/><link nonce="zQcdnLrPwtUu1QPPXR/ORA==" rel="stylesheet" href="../../../../../_next/static/css/a4c87e381fd61058.css" data-n-g=""/><link nonce="zQcdnLrPwtUu1QPPXR/ORA==" rel="preload" href="../../../../../_next/static/css/2facd84af36bff2e.css" as="style"/><link nonce="zQcdnLrPwtUu1QPPXR/ORA==" rel="stylesheet" href="../../../../../_next/static/css/2facd84af36bff2e.css" data-n-p=""/><link nonce="zQcdnLrPwtUu1QPPXR/ORA==" rel="preload" href="../../../../../_next/static/css/c413166e8b0da734.css" as="style"/><link nonce="zQcdnLrPwtUu1QPPXR/ORA==" rel="stylesheet" href="../../../../../_next/static/css/c413166e8b0da734.css" data-n-p=""/><link nonce="zQcdnLrPwtUu1QPPXR/ORA==" rel="preload" href="../../../../../_next/static/css/248e88462928fa2f.css" as="style"/><link nonce="zQcdnLrPwtUu1QPPXR/ORA==" rel="stylesheet" href="../../../../../_next/static/css/248e88462928fa2f.css" data-n-p=""/><link nonce="zQcdnLrPwtUu1QPPXR/ORA==" rel="preload" href="../../../../../_next/static/css/eb8a627e7f585420.css" as="style"/><link nonce="zQcdnLrPwtUu1QPPXR/ORA==" rel="stylesheet" href="../../../../../_next/static/css/eb8a627e7f585420.css" data-n-p=""/><noscript data-n-css="zQcdnLrPwtUu1QPPXR/ORA=="></noscript><script defer="" nonce="zQcdnLrPwtUu1QPPXR/ORA==" nomodule="" src="../../../../../_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="../../../../../_next/static/chunks/webpack-d326a7489defa990.js" nonce="zQcdnLrPwtUu1QPPXR/ORA==" defer=""></script><script src="../../../../../_next/static/chunks/framework-cc7effedd0fd3d95.js" nonce="zQcdnLrPwtUu1QPPXR/ORA==" defer=""></script><script src="../../../../../_next/static/chunks/main-ebfff3515213fa2f.js" nonce="zQcdnLrPwtUu1QPPXR/ORA==" defer=""></script><script src="../../../../../_next/static/chunks/pages/_app-4cd98c5be1eceb26.js" nonce="zQcdnLrPwtUu1QPPXR/ORA==" defer=""></script><script src="../../../../../_next/static/chunks/f69bbb46-eed95df46583a2d8.js" nonce="zQcdnLrPwtUu1QPPXR/ORA==" defer=""></script><script src="../../../../../_next/static/chunks/030d571f-c7510aa4f8d650e7.js" nonce="zQcdnLrPwtUu1QPPXR/ORA==" defer=""></script><script src="../../../../../_next/static/chunks/193-fdb54e47dd6b7c7b.js" nonce="zQcdnLrPwtUu1QPPXR/ORA==" defer=""></script><script src="../../../../../_next/static/chunks/756-04d1c95c632019ed.js" nonce="zQcdnLrPwtUu1QPPXR/ORA==" defer=""></script><script src="../../../../../_next/static/chunks/387-27526d5e8e2a9173.js" nonce="zQcdnLrPwtUu1QPPXR/ORA==" defer=""></script><script src="../../../../../_next/static/chunks/pages/blog/posts/[...slug]-896d627301783262.js" nonce="zQcdnLrPwtUu1QPPXR/ORA==" defer=""></script><script src="../../../../../_next/static/HkxA3M0ES7gp3V0n_0ecw/_buildManifest.js" nonce="zQcdnLrPwtUu1QPPXR/ORA==" defer=""></script><script src="../../../../../_next/static/HkxA3M0ES7gp3V0n_0ecw/_ssgManifest.js" nonce="zQcdnLrPwtUu1QPPXR/ORA==" defer=""></script></head><body class="dc-root g-root g-root_theme_dark"><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5M39N8J" title="Googletagmanager" height="0" width="0" style="display:none;visibility:hidden" loading="lazy"></iframe></noscript><div id="__next" data-reactroot=""><div class="layout"><div class="layout__content"><div class="g-root g-root_theme_dark pc-page-constructor"><div class="pc-page-constructor__wrapper"><div class="pc-layout"><div class="pc-Grid pc-navigation pc-layout__navigation"><div class="container-fluid "><div class="row"><div class="col"><nav><div class="pc-desktop-navigation__wrapper"><div class="pc-desktop-navigation__left"><div class="link" data-link-type="router"><span class="pc-logo pc-desktop-navigation__logo"><picture><img alt="Logo icon" src="../../../../../assets/logo/dc-logo-dark.svg" class="pc-logo__icon"/></picture><span class="pc-logo__text"></span></span></div></div><div class="pc-desktop-navigation__navigation-container"><div class="pc-overflow-scroller__container"><div class="pc-overflow-scroller pc-desktop-navigation__navigation"><div class="pc-overflow-scroller__wrapper" style="left:0"><ul class="pc-desktop-navigation__links"><li class="pc-navigation-item pc-navigation-item_menu-layout_desktop pc-desktop-navigation__item"><button class="dc-dropdown-navigation-item__control"><span class="dc-dropdown-navigation-item__title">Why DoubleCloud</span></button><div style="position:fixed;left:0;top:0" class="g-popup dc-dropdown-navigation-item__dropdown"><div class="g-popup__content dc-dropdown-navigation-item__dropdown-content-wrapper" tabindex="-1"><div class="group-list-content"><div class="row item-list-content"><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Performance" data-link-type="router" href="../../../../../performance-boost/index.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Performance</span><span class="navigation-popup-item__description">Get the best performance with the highest ROI</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Security" data-link-type="router" href="../../../../../security.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Security</span><span class="navigation-popup-item__description">Keep your data protected and maintain compliance</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="DoubleCloud vs. other solutions" data-link-type="router" href="../../../../../comparison/index.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">DoubleCloud vs. other solutions</span><span class="navigation-popup-item__description">Learn how DoubleCloud’s products compare to other solutions</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Customer stories" data-link-type="router" href="../../../../../resources/case-studies/index.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Customer stories</span><span class="navigation-popup-item__description">See our solutions in action</span></div></a></div></div><div class="group-list-content__banner"><picture><img alt="" src="../../../../../assets/doublecloud/menu-bar/menu-banner-dc-results.png.webp" class="group-list-content__image" style="width:300px;height:300px"/></picture><span class="yfm yfm_constructor"><a href='../../../../../performance-boost/index.html' target='_self'>Get more and spend less with DoubleCloud  →</a></span></div></div></div></div></li><li class="pc-navigation-item pc-navigation-item_menu-layout_desktop pc-desktop-navigation__item"><button class="dc-dropdown-navigation-item__control"><span class="dc-dropdown-navigation-item__title">Products</span></button><div style="position:fixed;left:0;top:0" class="g-popup dc-dropdown-navigation-item__dropdown"><div class="g-popup__content dc-dropdown-navigation-item__dropdown-content-wrapper" tabindex="-1"><div class="row item-list-content"><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Managed Service for ClickHouse®" data-link-type="router" href="../../../../../services/managed-clickhouse.html"><picture class="navigation-popup-item__icon-container"><img alt="" src="../../../../../assets/icons/dc-clickhouse.svg" class="navigation-popup-item__icon"/></picture><div class="navigation-popup-item__container navigation-popup-item__container_with-margin"><span class="navigation-popup-item__title">Managed Service for ClickHouse®</span><span class="navigation-popup-item__description">The fastest, most resource-efficient OLAP database for real-time analytics</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Managed Service for Apache Kafka®" data-link-type="router" href="../../../../../services/managed-kafka.html"><picture class="navigation-popup-item__icon-container"><img alt="" src="../../../../../assets/icons/dc-kafka.svg" class="navigation-popup-item__icon"/></picture><div class="navigation-popup-item__container navigation-popup-item__container_with-margin"><span class="navigation-popup-item__title">Managed Service for Apache Kafka®</span><span class="navigation-popup-item__description">A leading data streaming technology for large-scale, data-intensive applications</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Managed Service for Apache Airflow®" data-link-type="router" href="../../../../../services/managed-airflow/index.html"><picture class="navigation-popup-item__icon-container"><img alt="" src="../../../../../assets/icons/dc-airflow.svg" class="navigation-popup-item__icon"/></picture><div class="navigation-popup-item__container navigation-popup-item__container_with-margin"><span class="navigation-popup-item__title">Managed Service for Apache Airflow®</span><span class="navigation-popup-item__description">Open-source tool to orchestrate and monitor workflows</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Data Transfer" data-link-type="router" href="../../../../../services/doublecloud-transfer.html"><picture class="navigation-popup-item__icon-container"><img alt="" src="../../../../../assets/icons/dc-transfer.svg" class="navigation-popup-item__icon"/></picture><div class="navigation-popup-item__container navigation-popup-item__container_with-margin"><span class="navigation-popup-item__title">Data Transfer</span><span class="navigation-popup-item__description">No-code ELT tool for aggregating, collecting, and migrating data</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Data Visualization" data-link-type="router" href="../../../../../services/doublecloud-visualization.html"><picture class="navigation-popup-item__icon-container"><img alt="" src="../../../../../assets/icons/dc-data-vis.svg" class="navigation-popup-item__icon"/></picture><div class="navigation-popup-item__container navigation-popup-item__container_with-margin"><span class="navigation-popup-item__title">Data Visualization</span><span class="navigation-popup-item__description">Free tool to create, modify, and share dashboards and charts</span></div></a></div></div></div></div></li><li class="pc-navigation-item pc-navigation-item_menu-layout_desktop pc-desktop-navigation__item"><button class="dc-dropdown-navigation-item__control"><span class="dc-dropdown-navigation-item__title">Solutions</span></button><div style="position:fixed;left:0;top:0" class="g-popup dc-dropdown-navigation-item__dropdown"><div class="g-popup__content dc-dropdown-navigation-item__dropdown-content-wrapper" tabindex="-1"><div class="group-list-content"><div class="row item-list-content"><h4 class="item-list-content__title">By use case</h4><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Customer-facing analytics" data-link-type="router" href="../../../../../customer-facing-analytics/index.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Customer-facing analytics</span><span class="navigation-popup-item__description">Provide business insights for your clients or partners</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Real-time analytics" data-link-type="router" href="../../../../../solutions/real-time-analytics/index.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Real-time analytics</span><span class="navigation-popup-item__description">Build a data infrastructure to collect, process, and analyze data in real time</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Observability and monitoring" data-link-type="router" href="../../../../../solutions/observability-and-monitoring/index.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Observability and monitoring</span><span class="navigation-popup-item__description">Analyze terabytes of your logs, events, and traces with ease</span></div></a></div></div><div class="row item-list-content"><h4 class="item-list-content__title">By industry</h4><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="AdTech and MarTech data analytics" data-link-type="router" href="../../../../../solutions/adtech.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">AdTech and MarTech data analytics</span><span class="navigation-popup-item__description">Extract and analyze data from Meta ads, Google ads, LinkedIn ads, and others</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Analytics for mobile and gaming apps" data-link-type="router" href="../../../../../solutions/web-mobile-gaming-apps.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Analytics for mobile and gaming apps</span><span class="navigation-popup-item__description">Optimize and scale your mobile and gaming app analytics</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="EdTech data analytics" data-link-type="router" href="../../../../../solutions/edtech/index.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">EdTech data analytics</span><span class="navigation-popup-item__description">Improve online learning and identify new sales opportunities</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="FinTech data analytics" data-link-type="router" href="../../../../../solutions/fintech-real-time-analytics/index.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">FinTech data analytics</span><span class="navigation-popup-item__description">Manage and process large amounts of financial data efficiently</span></div></a></div></div></div></div></div></li><li class="pc-navigation-item pc-navigation-item_menu-layout_desktop pc-desktop-navigation__item"><button class="dc-dropdown-navigation-item__control dc-dropdown-navigation-item__control_selected"><span class="dc-dropdown-navigation-item__title">Resources</span></button><div style="position:fixed;left:0;top:0" class="g-popup dc-dropdown-navigation-item__dropdown"><div class="g-popup__content dc-dropdown-navigation-item__dropdown-content-wrapper" tabindex="-1"><div class="group-list-content"><div class="row item-list-content"><h4 class="item-list-content__title">Using DoubleCloud</h4><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="DoubleCloud API" href="../../../../../docs/en/public-api/index.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">DoubleCloud API</span><span class="navigation-popup-item__description">Read up on API tutorials and instructions</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Terraform" href="../../../../../docs/en/developer-resources/terraform/create-resources.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Terraform</span><span class="navigation-popup-item__description">Deploy and manage cloud resources with the infrastructure-as-code approach</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Status updates" data-link-type="router" href="https://status.double.cloud/"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Status updates</span><span class="navigation-popup-item__description">Check the current operational status of our services</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Support" data-link-type="router" href="../../../../../support/index.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Support</span><span class="navigation-popup-item__description">Learn more about our support tiers</span></div></a></div></div><div class="row item-list-content"><h4 class="item-list-content__title">Discover</h4><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Webinars" data-link-type="router" href="../../../../../webinars/index.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Webinars</span><span class="navigation-popup-item__description">Sign up for the next webinar or watch previous ones</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover navigation-popup-item__content_selected" aria-label="Blog" data-link-type="router" href="../../../../index.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Blog</span><span class="navigation-popup-item__description">Get insights from our team and the latest news</span></div></a></div></div><div class="group-list-content__banner"><picture><img alt="" src="../../../../../assets/doublecloud/menu-bar/menu-banners-dc-ebook.png.webp" class="group-list-content__image" style="width:300px;height:300px"/></picture><span class="yfm yfm_constructor"><a href='../../../../../resources/clickhouse-ebook/index.html' target='_self'>Grab your ebook  →</a></span></div></div></div></div></li><li class="pc-navigation-item pc-navigation-item_menu-layout_desktop pc-desktop-navigation__item"><button class="dc-dropdown-navigation-item__control"><span class="dc-dropdown-navigation-item__title">Company</span></button><div style="position:fixed;left:0;top:0" class="g-popup dc-dropdown-navigation-item__dropdown"><div class="g-popup__content dc-dropdown-navigation-item__dropdown-content-wrapper" tabindex="-1"><div class="row item-list-content"><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="About DoubleCloud" data-link-type="router" href="../../../../../company/about-us.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">About DoubleCloud</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Careers" data-link-type="router" href="../../../../../company/careers.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Careers</span></div></a></div><div class="col  col-12 navigation-popup-item item-list-content__item"><a class="navigation-popup-item__content navigation-popup-item__content_hover" aria-label="Contact us" data-link-type="router" href="../../../../../company/contact-us.html"><div class="navigation-popup-item__container"><span class="navigation-popup-item__title">Contact us</span></div></a></div></div></div></div></li><li class="pc-navigation-item pc-navigation-item_menu-layout_desktop pc-desktop-navigation__item"><a aria-label="Pricing" class="pc-navigation-item__content pc-navigation-item__content_type_link" data-link-type="router" href="../../../../../pricing.html"><div class="navigation-item"><span class="navigation-item__text">Pricing</span></div></a></li><li class="pc-navigation-item pc-navigation-item_menu-layout_desktop pc-desktop-navigation__item"><a href="../../../../../docs/index.html" aria-label="Documentation" class="pc-navigation-item__content pc-navigation-item__content_type_link" target="_self"><div class="navigation-item"><span class="navigation-item__text">Documentation</span></div></a></li></ul></div></div></div></div><div class="pc-desktop-navigation__right"><button type="button" aria-label="Button label" class="pc-control pc-control_size_l pc-control_theme_primary pc-mobile-menu-button"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="24" height="24" class="g-icon" fill="currentColor" stroke="none" data-qa="icon-test-id" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 16 16"><path fill="currentColor" fill-rule="evenodd" d="M1.25 3.25A.75.75 0 0 1 2 2.5h12A.75.75 0 0 1 14 4H2a.75.75 0 0 1-.75-.75Zm0 4.75A.75.75 0 0 1 2 7.25h12a.75.75 0 0 1 0 1.5H2A.75.75 0 0 1 1.25 8ZM2 12a.75.75 0 0 0 0 1.5h12a.75.75 0 0 0 0-1.5H2Z" clip-rule="evenodd"></path></svg></svg></button><ul class="pc-desktop-navigation__buttons"><li class="pc-navigation-item pc-navigation-item_menu-layout_desktop pc-desktop-navigation__item"><div class="link" data-link-type="router"><a class="g-button g-button_view_flat g-button_size_l g-button_pin_round-round pc-button-block pc-button-block_position_left pc-button-block_size_l pc-button-block_theme_flat pc-navigation-button pc-navigation-item__content pc-navigation-item__content_type_button" href="https://join.slack.com/t/double-cloud/shared_invite/zt-1pbz9lfte-5GoIX~8CmVYqmVQfRFPNdA" aria-disabled="false"><span class="g-button__text"><span class="pc-button-block__content"><img class="pc-button-block__image" src="../../../../../assets/icons/slack.svg" alt="Button image"/><span class="pc-button-block__text">Slack</span></span></span></a></div></li><li class="pc-navigation-item pc-navigation-item_menu-layout_desktop pc-desktop-navigation__item"><div class="link" data-link-type="router"><a class="g-button g-button_view_flat g-button_size_l g-button_pin_round-round pc-button-block pc-button-block_size_l pc-button-block_theme_flat pc-navigation-button pc-navigation-item__content pc-navigation-item__content_type_button" href="../real-time-analytics-kafka-clickhouse-integration.html#contact-us-form" aria-disabled="false"><span class="g-button__text"><span class="pc-button-block__content"><span class="pc-button-block__text">Contact us</span></span></span></a></div></li><li class="pc-navigation-item pc-navigation-item_menu-layout_desktop pc-desktop-navigation__item"><div class="link" data-link-type="router"><a class="g-button g-button_view_action g-button_size_l g-button_pin_round-round pc-button-block pc-button-block_size_l pc-button-block_theme_accent pc-navigation-button pc-navigation-item__content pc-navigation-item__content_type_button" href="https://app.double.cloud" aria-disabled="false"><span class="g-button__text"><span class="pc-button-block__content"><span class="pc-button-block__text">Console</span></span></span></a></div></li></ul></div></div><div></div></nav></div></div></div></div><main class="pc-layout__content"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><header class="pc-header-block pc-header-block_media-view_full"><div class="pc-header-block__background pc-header-block__background_media" style="background-color:#000000"><div class="pc-Media pc-header-block__background-media" style="background-color:#000000"><div style="transform:"><div class="pc-storage-background-image pc-media-component-image__item pc-header-block__image" data-qa="background-image"><picture data-qa="background-image-image"><img fetchpriority="high" alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-cover.png" class="pc-storage-background-image__img"/></picture></div></div></div></div><div class="pc-Grid"><div class="container-fluid pc-header-block__container-fluid"><div class="row pc-header-block__breadcrumbs"><div class="col"><div class="pc-header-breadcrumbs pc-header-breadcrumbs_theme_light" aria-label="You are here:"><div class="pc-header-breadcrumbs__item"><a href="../../../../index.html" class="pc-header-breadcrumbs__text">Blog</a></div><div class="pc-header-breadcrumbs__item"><a href="../../../../index.html%3Ftags=insights.html" class="pc-header-breadcrumbs__text">Insights</a></div></div></div></div><div class="row"><div class="col col-reset pc-header-block__content-wrapper"><div class="row"><div class="col pc-header-block__content pc-header-block__content_offset_default pc-header-block__content_theme_light pc-header-block__content_vertical-offset_l"><div class="col  col-lg-6 col-sm-12 col-md-8 col-12 pc-header-block__content-inner"><h1 class="pc-header-block__title" id="g-uniq-1224870"><span>Clickstream analytics case study. Part I: Kafka -> Data Transfer -> ClickHouse</span></h1><div class="pc-header-block__description"><div class="yfm yfm_constructor yfm_constructor_theme_light"><p>Written By: Igor Mosyagin, Developer Advocate at&nbsp;DoubleCloud</p></div></div><div class="bc-post-info__container bc-post-info__container_theme_light"><div class="bc-post-info__item bc-post-info__item_size_s" data-qa="blog-header-meta-container-date">September 6, 2024</div><div class="bc-post-info__item bc-post-info__item_size_s" data-qa="blog-header-meta-container-reading-time"><span class="bc-post-info__icon"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="16" height="16" class="g-icon bc-post-info__icon-color" fill="currentColor" stroke="none" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 17" fill="currentColor" aria-hidden="true"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 16.004a8 8 0 1 1 0-16 8 8 0 0 1 0 16Zm0-2a6 6 0 1 0 0-12 6 6 0 0 0 0 12Zm3.357-3.736a1 1 0 0 0-.342-1.372L9 7.688V5.004a1 1 0 0 0-2 0v3.25a1 1 0 0 0 .486.857l2.5 1.5a1 1 0 0 0 1.371-.343Z"></path></svg></svg></span>15 mins to read</div><div class="bc-post-info__item"><div class="bc-post-info__icon"><div class="g-popover gc-share-popover bc-post-info__share"><button class="gc-share-popover__container bc-post-info__switcher bc-post-info__switcher_theme_light" aria-expanded="false" aria-controls="g-uniq-1224871" aria-describedby="g-uniq-1224871"><div class="gc-share-popover__icon-container"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="16" height="16" class="g-icon gc-share-popover__icon bc-post-info__share-icon" fill="currentColor" stroke="none" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" fill="currentColor" aria-hidden="true"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.798 3.16a.5.5 0 0 0 .363.842H7V9a1 1 0 0 0 2 0V4.002h1.839a.5.5 0 0 0 .363-.844L8.363.156a.5.5 0 0 0-.726 0l-2.84 3.002.001.001ZM13 7a1 1 0 0 1 2 0v6.5a1.5 1.5 0 0 1-1.5 1.5h-11A1.5 1.5 0 0 1 1 13.5V7a1 1 0 0 1 2 0v6h10V7Z"></path></svg></svg></div><div class="gc-share-popover__title">Share</div></button></div></div></div></div></div></div></div></div></div></div></div></header></section><div class="pc-Grid"><div class="container-fluid "><div class="row pc-constructor-row"><div class="col"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><h2 id="intro"><a href="../real-time-analytics-kafka-clickhouse-integration.html#intro" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Intro</span></a>Intro</h2>
<p>Welcome to&nbsp;this series of&nbsp;posts exploring a&nbsp;real-time analytics use case. The series covers various aspects of&nbsp;setting up&nbsp;a&nbsp;real-time analytics platform using DoubleCloud managed services, from data ingestion to&nbsp;aggregation computation, and finally, to&nbsp;dashboards based on&nbsp;those data marts.</p>
<p>This first post focuses on&nbsp;the initial setup and data loading using ClickHouse, Apache Kafka, and DoubleCloud&rsquo;s Data Transfer.</p>
<h2 id="data-solution-overview"><a href="../real-time-analytics-kafka-clickhouse-integration.html#data-solution-overview" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Data Solution overview</span></a>Data Solution overview</h2>
<p>By&nbsp;the end of&nbsp;the series, we&nbsp;will have built a&nbsp;setup that enables us&nbsp;to&nbsp;ingest and make decisions based on&nbsp;clickstream data. The overall architecture of&nbsp;our data platform looks like this schematically:</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-1-2.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-1-2.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>Quick navigation:</p>
<ul>
<li><a href="../real-time-analytics-kafka-clickhouse-integration.html#intro">Intro</a></li>
<li><a href="../real-time-analytics-kafka-clickhouse-integration.html#data-solution-overview">Data Solution overview</a></li>
<li><a href="../real-time-analytics-kafka-clickhouse-integration.html#problem-outline">Problem outline</a></li>
<li><a href="../real-time-analytics-kafka-clickhouse-integration.html#sample-event">Sample event</a></li>
<li><a href="../real-time-analytics-kafka-clickhouse-integration.html#setup-infrastructure">Setup Infrastructure</a></li>
<li><a href="../real-time-analytics-kafka-clickhouse-integration.html#setup-transfer-endpoints">Setup transfer endpoints</a></li>
<li><a href="../real-time-analytics-kafka-clickhouse-integration.html#creating-and-activating-the-transfer">Creating and activating the Transfer</a></li>
<li><a href="../real-time-analytics-kafka-clickhouse-integration.html#producer-script">Producer script</a></li>
<li><a href="../real-time-analytics-kafka-clickhouse-integration.html#sanity-checks-to-ensure-everything-works-as-expected">Sanity checks to&nbsp;ensure everything works as&nbsp;expected</a></li>
<li><a href="../real-time-analytics-kafka-clickhouse-integration.html#adding-transformation">Adding transformation</a></li>
<li><a href="../real-time-analytics-kafka-clickhouse-integration.html#check-the-final-result">Check the final result</a></li>
<li><a href="../real-time-analytics-kafka-clickhouse-integration.html#wrap-up">Wrap up</a></li>
</ul></div></section></div></div></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>In&nbsp;the diagram, the white part represents an&nbsp;external data provider (such as&nbsp;a&nbsp;web performance monitoring tool), while everything else consists of&nbsp;DoubleCloud managed services. We&nbsp;will use a&nbsp;simple Python script to&nbsp;send data. This first part focuses on&nbsp;data ingestion, the initial setup of&nbsp;our Kafka server, and the data loading process for ClickHouse:</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-2-2.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-2-2.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>The upcoming parts of&nbsp;the series will focus on&nbsp;aggregations and visualization. While we&nbsp;will address performance when relevant, the primary goal of&nbsp;the series is&nbsp;to&nbsp;describe connecting the various components together.</p>
<h2 id="problem-outline"><a href="../real-time-analytics-kafka-clickhouse-integration.html#problem-outline" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Problem outline</span></a>Problem outline</h2>
<p>One of&nbsp;the common tasks in&nbsp;real-time analytics is&nbsp;performing aggregations. We&nbsp;have clickstream data and want to&nbsp;visualize some basic metrics related to&nbsp;user activity on&nbsp;the website. In&nbsp;this example, which will be&nbsp;used throughout the entire series, we&nbsp;will use a&nbsp;subset of&nbsp;fields from our clickstream data to&nbsp;calculate how many products were purchased during specific hours of&nbsp;the day.</p>
<h2 id="sample-event"><a href="../real-time-analytics-kafka-clickhouse-integration.html#sample-event" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Sample event</span></a>Sample event</h2>
<p>Here&rsquo;s an&nbsp;example event from our data source, representing user interactions with products in&nbsp;a&nbsp;marketplace. This event is&nbsp;already enriched with additional information about the user and the item they interacted with:</p>

    <div class="yfm-clipboard">
    <pre><code class="hljs json"><span class="hljs-punctuation">{</span>
<span class="hljs-attr">"basket_price"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">""</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"detectedCorruption"</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"detectedDuplicate"</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"eventType"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"itemViewEvent"</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"firstInSession"</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"item_id"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"bx_VHZvTOyk_CYNTZGlxyopNGYodgtybLKqToopjOqbT"</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"item_price"</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4876</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"item_url"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"https://mu3bxs.webshop24.eu/katalog/item/t-shirt-female-temptation/"</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"location"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"https://mu3bxs.webshop24.eu/"</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"pageViewId"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"0:qawVTkAI:IyqIWWkimHqgvBGCbeMMIoosmXiuLcvW"</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"partyId"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"0:ckQoIhoa:PtdjtCnxGtRzfXvovHcDtltPSaDzpvxM"</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"referer"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"https://mu3bxs.webshop24.eu//katalog/item/slippers-pink-paradise/"</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"remoteHost"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"test0"</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"sessionId"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"0:ZSMAmydy:yqxDDTWQfbRtrauPYAAIGQsCVubHrdov"</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"timestamp"</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1545127200000</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"userAgentName"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36"</span>
<span class="hljs-punctuation">}</span>
</code></pre>

    <svg width="16" height="16" viewBox="0 0 24 24" class="yfm-clipboard-button" data-animation="15">
        <path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path>
        <path stroke="currentColor" fill="transparent" stroke-width="1.5" d="M9.5 13l3 3l5 -5" visibility="hidden">
            <animate id="visibileAnimation-15" attributeName="visibility" from="hidden" to="visible" dur="0.2s" fill="freeze" begin></animate>
            <animate id="hideAnimation-15" attributeName="visibility" from="visible" to="hidden" dur="1s" begin="visibileAnimation-15.end+1" fill="freeze"></animate>
        </path>
    </svg>
    </div>
<p>For the purpose of&nbsp;our example pipeline, we&nbsp;will concentrate on&nbsp;a&nbsp;subset of&nbsp;the event&rsquo;s fields and set our ingestion pipeline to&nbsp;use only the ones we&rsquo;re interested&nbsp;in. To&nbsp;compute aggregated statistics, we&nbsp;will need the following fields:</p>
<ul>
<li>
<p><code>partyId</code> (string key, denoting global userId)</p>
</li>
<li>
<p><code>sessionId</code> (string key, used to&nbsp;mark the same user session)</p>
</li>
<li>
<p><code>item_price</code> (integer representing the price of&nbsp;an&nbsp;item)</p>
</li>
<li>
<p><code>eventType</code> (string field for the type of&nbsp;event)</p>
</li>
<li>
<p><code>detectedDuplicate</code> and <code>detectedCorruption</code> (boolean fields from upcoming data enrichment systems that will be&nbsp;used to&nbsp;filter data)</p>
</li>
</ul>
<p>Everything else is&nbsp;unnecessary for our example use case, but it&rsquo;s helpful to&nbsp;know what those fields are in&nbsp;case there is&nbsp;a&nbsp;need for further analysis later.</p>
<p>The Python code, along with sample data and instructions on&nbsp;how to&nbsp;run it, can be&nbsp;found <a href="https://github.com/doublecloud/showcase-webshop-clickstream-aggregation">in&nbsp;this repository</a>.</p></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><h2 id="setup-infrastructure"><a href="../real-time-analytics-kafka-clickhouse-integration.html#setup-infrastructure" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Setup infrastructure</span></a>Setup infrastructure</h2>
<h3 id="kafka-cluster"><a href="../real-time-analytics-kafka-clickhouse-integration.html#kafka-cluster" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Kafka cluster</span></a>Kafka cluster</h3>
<p>We&nbsp;will use Kafka as&nbsp;our ingestion layer. For the purposes of&nbsp;this series, we&nbsp;can go&nbsp;with the default options: select the eu-central-1 zone and choose the smallest possible configuration. The only change I&nbsp;would personally recommend is&nbsp;opting for an&nbsp;ARM architecture, as&nbsp;it&nbsp;tends to&nbsp;perform slightly better, as&nbsp;highlighted in&nbsp;our article on&nbsp;this topic: <a href="../../06/benchmarking-apache-kafka-performance-per-price.html">Benchmarking Apache Kafka: performance per price</a>.</p>
<p>Simply pick a&nbsp;cluster name you&rsquo;re comfortable with, select a&nbsp;recent Kafka version (3.5), and you&rsquo;re all set!</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-3.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-3.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"><div class="bc-layout__item"><div class="pc-card-base-block pc-card-base-block_border_shadow pc-background-card pc-background-card_padding_l pc-background-card_theme_default"><div class="pc-card-base-block__body"><div class="pc-card-base-block__content pc-background-card__content"><div class="pc-storage-background-image pc-background-card__image" data-qa="background-image"><picture data-qa="background-image-image"><source srcSet="../../../../../assets/doublecloud/cards/card-service-kafka-v3.png.webp" type="image/webp" data-qa="background-image-image-desktop-source-compressed"/><img alt="" src="../../../../../assets/doublecloud/cards/card-service-kafka-v3.png" class="pc-storage-background-image__img"/></picture></div><div class="col  col-12 col-md-12 col-reset pc-content pc-content_size_s pc-content_theme_default pc-content_control-position_default"><div class="pc-title pc-content__title" id="g-uniq-1224873"><div class="col  col-12 col-reset"><h3 class="pc-title-item pc-title-item_size_s pc-title-item_reset-margin" data-qa="undefined-header"><span class="pc-title-item__text">Managed Service for Apache Kafka</span></h3></div></div><div class="pc-content__text"><div class="yfm yfm_constructor yfm_constructor_size_s"><p>Fully managed, secure, and highly available service for distributed delivery, storage, and real-time data processing.</p></div></div><div class="pc-buttons pc-buttons_size_s pc-content__buttons pc-content__buttons_size_s"><a aria-describedby="g-uniq-1224873" class="g-button g-button_view_action g-button_size_l g-button_pin_round-round pc-button-block pc-button-block_size_m pc-button-block_theme_action pc-buttons__button" href="../../../../../services/managed-kafka.html" aria-disabled="false"><span class="g-button__text"><span class="pc-button-block__content"><span class="pc-button-block__text">Learn more</span></span></span></a></div></div></div></div></div></div></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>Provisioning should take a&nbsp;few minutes (we&nbsp;can create the ClickHouse cluster in&nbsp;the meantime). Once the cluster is&nbsp;up&nbsp;and running, let&rsquo;s navigate to&nbsp;cluster settings and create a&nbsp;topic for our events.</p>
<h4 id="kafka-topic-for-incoming-messages"><a href="../real-time-analytics-kafka-clickhouse-integration.html#kafka-topic-for-incoming-messages" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Kafka topic for incoming messages</span></a>Kafka topic for incoming messages</h4>
<p>We&nbsp;will be&nbsp;using a&nbsp;standard architectural pattern of&nbsp;having a&nbsp;single topic per schema, meaning that each different schema of&nbsp;messages will be&nbsp;assigned to&nbsp;a&nbsp;separate topic. Therefore, we&nbsp;need to&nbsp;create a&nbsp;topic for incoming messages, which can be&nbsp;done through the same cluster control interface.</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-4.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-4.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>For the purpose of&nbsp;this tutorial, our load is&nbsp;non-threatening, so&nbsp;we&nbsp;can use a&nbsp;simple topic with just one partition and a&nbsp;replication factor of&nbsp;one.</p>
<h4 id="allowlist-caveat"><a href="../real-time-analytics-kafka-clickhouse-integration.html#allowlist-caveat" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">AllowList caveat</span></a>AllowList caveat</h4>
<p>To&nbsp;simplify testing, DoubleCloud adds your IP&nbsp;address to&nbsp;the <strong>ALLOW LIST</strong> in&nbsp;the cluster settings. Keep this in&nbsp;mind if&nbsp;you frequently switch Wi-Fi networks while working from your laptop.</p></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><h3 id="clickhouse-cluster"><a href="../real-time-analytics-kafka-clickhouse-integration.html#clickhouse-cluster" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">ClickHouse cluster</span></a>ClickHouse cluster</h3>
<p>For the ClickHouse cluster, let&rsquo;s select the same availability zone and opt for the smallest possible setup: 1&nbsp;replica and 1&nbsp;shard, resulting in&nbsp;a&nbsp;single ARM node with just 32&nbsp;GB&nbsp;of&nbsp;storage. While you would typically want a&nbsp;more robust configuration for production, these defaults are sufficient for our current needs. We&rsquo;ll discuss scaling a&nbsp;bit in&nbsp;future parts of&nbsp;this series.</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-5.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-5.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"><div class="bc-layout__item"><div class="pc-card-base-block pc-card-base-block_border_shadow pc-background-card pc-background-card_padding_l pc-background-card_theme_default"><div class="pc-card-base-block__body"><div class="pc-card-base-block__content pc-background-card__content"><div class="pc-storage-background-image pc-background-card__image" data-qa="background-image"><picture data-qa="background-image-image"><source srcSet="../../../../../assets/doublecloud/cards/card-service-clickhouse-v3.png.webp" type="image/webp" data-qa="background-image-image-desktop-source-compressed"/><img alt="" src="../../../../../assets/doublecloud/cards/card-service-clickhouse-v3.png" class="pc-storage-background-image__img"/></picture></div><div class="col  col-12 col-md-12 col-reset pc-content pc-content_size_s pc-content_theme_default pc-content_control-position_default"><div class="pc-title pc-content__title" id="g-uniq-1224875"><div class="col  col-12 col-reset"><h3 class="pc-title-item pc-title-item_size_s pc-title-item_reset-margin" data-qa="undefined-header"><span class="pc-title-item__text">Managed Service for ClickHouse</span></h3></div></div><div class="pc-content__text"><div class="yfm yfm_constructor yfm_constructor_size_s"><p>Fully managed service from the creators of&nbsp;the world&rsquo;s 1st managed ClickHouse. Backups, 24/7 monitoring, auto-scaling, and updates.</p></div></div><div class="pc-buttons pc-buttons_size_s pc-content__buttons pc-content__buttons_size_s"><a aria-describedby="g-uniq-1224875" class="g-button g-button_view_action g-button_size_l g-button_pin_round-round pc-button-block pc-button-block_size_m pc-button-block_theme_action pc-buttons__button" href="../../../../../services/managed-clickhouse.html" aria-disabled="false"><span class="g-button__text"><span class="pc-button-block__content"><span class="pc-button-block__text">Learn more</span></span></span></a></div></div></div></div></div></div></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>Choose a&nbsp;reasonable name for the cluster and select a&nbsp;relevant version. The cluster creation UI&nbsp;defaults to&nbsp;the latest LTS version, but there&rsquo;s nothing stopping us&nbsp;from opting for a&nbsp;more recent one.</p>
<h4 id="clickhouse-database"><a href="../real-time-analytics-kafka-clickhouse-integration.html#clickhouse-database" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">ClickHouse database</span></a>ClickHouse database</h4>
<p>While we&nbsp;can use the default database for ClickHouse, it&nbsp;makes sense to&nbsp;create a&nbsp;different one for our application. Let&rsquo;s go&nbsp;ahead and do&nbsp;that. There are multiple ways to&nbsp;access our cluster, but the easiest method is&nbsp;to&nbsp;use the WebSQL interface. From the cluster interface, click on&nbsp;the <strong>WebSQL</strong> button to&nbsp;open the interface in&nbsp;the new tab.</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-6.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-6.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>This will automatically connect to&nbsp;the cluster and authorize with admin credentials. Clicking on&nbsp;any entity in&nbsp;the left tree menu will open the query editor. Execute the following code to&nbsp;create a&nbsp;new database:</p>

    <div class="yfm-clipboard">
    <pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> DATABASE webshop;
</code></pre>

    <svg width="16" height="16" viewBox="0 0 24 24" class="yfm-clipboard-button" data-animation="3">
        <path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path>
        <path stroke="currentColor" fill="transparent" stroke-width="1.5" d="M9.5 13l3 3l5 -5" visibility="hidden">
            <animate id="visibileAnimation-3" attributeName="visibility" from="hidden" to="visible" dur="0.2s" fill="freeze" begin></animate>
            <animate id="hideAnimation-3" attributeName="visibility" from="visible" to="hidden" dur="1s" begin="visibileAnimation-3.end+1" fill="freeze"></animate>
        </path>
    </svg>
    </div></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-7.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-7.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>I&nbsp;suggest naming the new database <strong>webshop</strong>, and I&nbsp;will use this name in&nbsp;the examples moving forward. Now that we&nbsp;have our source and destination set up, let&rsquo;s create a&nbsp;<strong>Data Transfer</strong> pipeline to&nbsp;connect them.</p>
<h4 id="allowlist-caveat"><a href="../real-time-analytics-kafka-clickhouse-integration.html#allowlist-caveat" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">AllowList caveat</span></a>AllowList caveat</h4>
<p>Similar to&nbsp;the Kafka cluster, DoubleCloud adds your IP&nbsp;address to&nbsp;the <strong>ALLOW LIST</strong> in&nbsp;the cluster settings behind the scenes. Keep this in&nbsp;mind if&nbsp;you frequently switch Wi-Fi networks while working from your laptop. It&nbsp;is&nbsp;advised not to&nbsp;open your cluster to&nbsp;the world carelessly, even for short-term testing purposes.</p>
<h2 id="setup-transfer-endpoints"><a href="../real-time-analytics-kafka-clickhouse-integration.html#setup-transfer-endpoints" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Setup transfer endpoints</span></a>Setup transfer endpoints</h2>
<p>DoubleCloud provides a&nbsp;convenient way to&nbsp;ingest data from Kafka to&nbsp;ClickHouse through a&nbsp;tool called <a href="../../../../../services/doublecloud-transfer.html">Data Transfer</a>. We&nbsp;will use <strong>Transfer</strong> to&nbsp;read data from our <strong>Kafka topic</strong> (referred to&nbsp;as&nbsp;the source endpoint in&nbsp;Transfer&rsquo;s terminology) and publish it&nbsp;to&nbsp;<strong>ClickHouse</strong> (the target endpoint in&nbsp;Transfer&rsquo;s terminology). Let&rsquo;s set it&nbsp;up!</p>
<h3 id="kafka-transport-source-endpoint"><a href="../real-time-analytics-kafka-clickhouse-integration.html#kafka-transport-source-endpoint" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Kafka: Transport source endpoint</span></a>Kafka: Transport source endpoint</h3>
<p>Navigate to&nbsp;the <strong>Transfer</strong> page, switch to&nbsp;the <strong>Endpoint</strong> tab, and create a&nbsp;source endpoint. Select <strong>Kafka</strong> as&nbsp;the source type in&nbsp;the dropdown and give it&nbsp;a&nbsp;reasonable name (this name will be&nbsp;used internally by&nbsp;Transfer).</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-8.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-8.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>Select the recently created Kafka cluster and use the credentials to&nbsp;connect to&nbsp;it&nbsp;via SASL. To&nbsp;make the endpoint functional, add the topic that was created earlier.</p>
<h4 id="json-fields"><a href="../real-time-analytics-kafka-clickhouse-integration.html#json-fields" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">JSON fields</span></a>JSON fields</h4>
<p>Since the initial analysis of&nbsp;event data showed that we&nbsp;don&rsquo;t need all the fields, we&nbsp;can include only the ones we&nbsp;are interested&nbsp;in. This can be&nbsp;done using the <strong>Advanced settings</strong> tab, where we&nbsp;can specify a&nbsp;JSON conversion rule with a&nbsp;list of&nbsp;relevant fields. Here&rsquo;s what I&nbsp;ended up&nbsp;with:</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-9.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-9.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>Additionally, since I&nbsp;might be&nbsp;interested in&nbsp;other fields later, I&rsquo;ll make sure that a&nbsp;corresponding option is&nbsp;enabled, just in&nbsp;case.</p>
<h3 id="clickhouse-transport-target-endpoint"><a href="../real-time-analytics-kafka-clickhouse-integration.html#clickhouse-transport-target-endpoint" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">ClickHouse: Transport target endpoint</span></a>ClickHouse: Transport target endpoint</h3>
<p>Creating the target endpoint is&nbsp;straightforward as&nbsp;well. There&rsquo;s no&nbsp;need for any additional setup; simply select the connection type, choose the correct cluster from the dropdown menu, and specify the target database (schema).</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-10.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-10.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>Now that both endpoints are set up, we&nbsp;need to&nbsp;create the transfer itself.</p>
<h2 id="creating-and-activating-the-transfer"><a href="../real-time-analytics-kafka-clickhouse-integration.html#creating-and-activating-the-transfer" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Creating and activating the Transfer</span></a>Creating and activating the Transfer</h2>
<p>We&nbsp;need to&nbsp;specify the created endpoints, choose a&nbsp;name, and that&rsquo;s&nbsp;it. Everything else can be&nbsp;left at&nbsp;the default settings. Click <strong>&ldquo;Submit&rdquo;</strong> and grab a&nbsp;cup of&nbsp;tea while the transfer is&nbsp;being created.</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-11.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-11.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>Once the transfer is&nbsp;created, we&nbsp;need to&nbsp;activate it&nbsp;and ensure it&nbsp;is&nbsp;running (its status should change accordingly).</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-12.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-12.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><h2 id="producer-script"><a href="../real-time-analytics-kafka-clickhouse-integration.html#producer-script" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Producer script</span></a>Producer script</h2>
<p>To&nbsp;test the pipeline, we&nbsp;will be&nbsp;producing 1,000 events from a&nbsp;file using a&nbsp;Python script. <a href="https://github.com/doublecloud/showcase-webshop-clickstream-aggregation">You can check the source here</a>.</p>
<p>To&nbsp;run the script, install the required packages, set the environment variables for cluster access, and execute the following command in&nbsp;the terminal:</p>

    <div class="yfm-clipboard">
    <pre><code class="hljs python">clickstream/produce_events.py
</code></pre>

    <svg width="16" height="16" viewBox="0 0 24 24" class="yfm-clipboard-button" data-animation="9">
        <path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path>
        <path stroke="currentColor" fill="transparent" stroke-width="1.5" d="M9.5 13l3 3l5 -5" visibility="hidden">
            <animate id="visibileAnimation-9" attributeName="visibility" from="hidden" to="visible" dur="0.2s" fill="freeze" begin></animate>
            <animate id="hideAnimation-9" attributeName="visibility" from="visible" to="hidden" dur="1s" begin="visibileAnimation-9.end+1" fill="freeze"></animate>
        </path>
    </svg>
    </div>
<p>This will produce 1,000 events from the file <strong>events1000.jsonl</strong>. Refer to&nbsp;the <code>README</code> if&nbsp;you want to&nbsp;customize something, encounter any issues or&nbsp;if&nbsp;you want to&nbsp;manipulate the data first, such as&nbsp;moving it&nbsp;in&nbsp;time if&nbsp;needed.</p>
<h2 id="sanity-checks-to-ensure-everything-works-as-expected"><a href="../real-time-analytics-kafka-clickhouse-integration.html#sanity-checks-to-ensure-everything-works-as-expected" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Sanity checks to&nbsp;ensure everything works as&nbsp;expected</span></a>Sanity checks to&nbsp;ensure everything works as&nbsp;expected</h2>
<p>Let&rsquo;s perform some queries from the WebSQL interface to&nbsp;check our data. If&nbsp;we&nbsp;open WebSQL Query editor, we&nbsp;can see that all 1,000 events have arrived:</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-13.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-13.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>The next logical step is&nbsp;to&nbsp;verify that the timestamps are in&nbsp;the expected format:</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-14.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-14.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>It&nbsp;appears that the dates are slightly too futuristic. A&nbsp;common issue with numeric timestamps from different systems is&nbsp;that they might use different time formats. For example, one system might use microseconds while another uses seconds. Let&rsquo;s see if&nbsp;dividing the timestamp resolves the issue:</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-15.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-15.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>And indeed, it&nbsp;does! We&nbsp;now have two options:</p>
<ul>
<li>Account for the fact that our timestamps need special treatment before proceeding with the analysis.</li>
<li>Transform the timestamps upon ingestion.</li>
</ul>
<p>Typical data modeling approach is&nbsp;to&nbsp;choose the first option, where you don&rsquo;t modify data at&nbsp;the ingestion <strong>&ldquo;source&rdquo;</strong> level and instead perform preparation in&nbsp;the next stage.</p>
<p>However, in&nbsp;modern data pipelines, it&nbsp;is&nbsp;generally acceptable to&nbsp;perform simple transformations during ingestion, as&nbsp;long as&nbsp;they are indeed straightforward. Thankfully, Transfer is&nbsp;capable of&nbsp;doing just that!</p>
<h2 id="adding-transformation"><a href="../real-time-analytics-kafka-clickhouse-integration.html#adding-transformation" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Adding transformation</span></a>Adding transformation</h2>
<p>If&nbsp;we&nbsp;go&nbsp;back to&nbsp;our transfer and open <strong>Edit</strong> view, we&rsquo;ll find a&nbsp;button labeled <strong>&ldquo;Transformation&rdquo;</strong> towards the end of&nbsp;the page:</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-16.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-16.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>This humble little feature is&nbsp;exactly what we&nbsp;need for our transformation. Transfer supports multiple ways to&nbsp;adjust your data as&nbsp;it&nbsp;moves between endpoints. We&nbsp;will use the on-the-fly SQL processor. Click on&nbsp;the button and select <strong>&ldquo;SQL&rdquo;</strong> from the Transformer dropdown. I&rsquo;ll create a&nbsp;new field called <strong>&ldquo;my_ts&rdquo;</strong> that will hold the original timestamp divided by&nbsp;1,000:</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-17.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-17.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><p>By&nbsp;the way, Transfer allows you to&nbsp;stack multiple transformations in&nbsp;a&nbsp;chain of&nbsp;operations if&nbsp;you wish. However, there are some limitations to&nbsp;what is&nbsp;possible and, more importantly, what should be&nbsp;done at&nbsp;this step. Keep in&nbsp;mind that these operations are effectively hidden from your view, so&nbsp;you should avoid extensive data transformations here and instead leave that to&nbsp;your ETL processes in&nbsp;the next stage of&nbsp;the data processing pipeline.</p>
<h2 id="check-the-final-result"><a href="../real-time-analytics-kafka-clickhouse-integration.html#check-the-final-result" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Check the final result</span></a>Check the final result</h2>
<p>Update the transfer, drop the table (since we&nbsp;are altering the scheme, this is&nbsp;the easiest way to&nbsp;update it), produce new data, and voil&agrave;! We&nbsp;have our timestamp in&nbsp;expected format and within the correct century.</p></div></section></div></div><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-media-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l bc-media__container"><div class="bc-media__border" data-qa="blog-media-content"><div class="pc-Media bc-media__content"><picture><source srcSet="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-18.png.webp" type="image/webp"/><img alt="" src="../../../../../assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-18.png" class="pc-media-component-image__item bc-media__image"/></picture></div></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-layout-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_xs"><div class="row bc-layout__row no-gutter"><div class="col  col-12 col-lg-8  order-3 order-lg-1 bc-layout__left-col"><div class="bc-layout__item"><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-yfm-block"><section class="bc-wrapper bc-wrapper_padding-top_xs bc-wrapper_padding-bottom_l"><div class="yfm yfm_blog yfm_reset_paddings yfm_no-list-reset"><h2 id="wrap-up"><a href="../real-time-analytics-kafka-clickhouse-integration.html#wrap-up" class="yfm-anchor" aria-hidden="true"><span class="visually-hidden">Wrap up</span></a>Wrap up</h2>
<p>In&nbsp;just a&nbsp;few clicks, we&nbsp;have created a&nbsp;Kafka cluster, a&nbsp;ClickHouse cluster, and a&nbsp;Transfer pipeline with on-the-fly data transformation that now ingests incoming data in&nbsp;our database. We&nbsp;have everything ready to&nbsp;start computing aggregates, which we&nbsp;will cover in&nbsp;the next part. Stay tuned for Part II!</p>
<p>If&nbsp;you have any questions or&nbsp;would like to&nbsp;discuss this series further, feel free to&nbsp;<a href="https://join.slack.com/t/double-cloud/shared_invite/zt-1pbz9lfte-5GoIX~8CmVYqmVQfRFPNdA">reach out on&nbsp;Slack</a>.</p></div></section></div></div></div><div class="col  col-12 col-lg-3  offset-0 offset-lg-1  order-2 order-lg-2 bc-layout__right-col"></div></div></section></div><div class="col col-reset pc-block-base pc-block-base_indentTop_l pc-block-base_indentBottom_l pc-constructor-block pc-constructor-block_type_content-layout-block"><div class="pc-content-layout-block pc-content-layout-block_size_l pc-content-layout-block_theme_default pc-content-layout-block_background"><div class="col  col-12 col-md-8 col-reset pc-content pc-content_size_l pc-content_centered pc-content_theme_default pc-content-layout-block__content"><div class="pc-title pc-content__title" id="g-uniq-1224877"><div class="col  col-12 col-reset"><h2 class="pc-title-item pc-title-item_size_m pc-title-item_reset-margin" data-qa="undefined-header"><span class="pc-title-item__text">Get started with DoubleCloud</span></h2></div></div><div class="pc-buttons pc-buttons_size_l pc-content__buttons pc-content__buttons_size_l"><a aria-describedby="g-uniq-1224877" class="g-button g-button_view_action g-button_size_xl g-button_pin_round-round pc-button-block pc-button-block_size_xl pc-button-block_theme_accent pc-buttons__button" href="https://auth.double.cloud/s/signup" aria-disabled="false"><span class="g-button__text"><span class="pc-button-block__content"><span class="pc-button-block__text">Start free trial</span></span></span></a><a aria-describedby="g-uniq-1224877" class="g-button g-button_view_outlined g-button_size_xl g-button_pin_round-round pc-button-block pc-button-block_size_xl pc-button-block_theme_pseudo pc-buttons__button" href="../real-time-analytics-kafka-clickhouse-integration.html#contact-us-form" aria-disabled="false"><span class="g-button__text"><span class="pc-button-block__content"><span class="pc-button-block__text">Contact us</span></span></span></a></div></div><div class="pc-content-layout-block__background"><div class="pc-storage-background-image pc-content-layout-block__background-item" style="background-color:#CA1551" data-qa="background-image"><picture data-qa="background-image-image"><source srcSet="../../../../../assets/doublecloud/doublecloud-cover-5.png.webp" type="image/webp" data-qa="background-image-image-desktop-source-compressed"/><img alt="" src="../../../../../assets/doublecloud/doublecloud-cover-5.png" class="pc-storage-background-image__img" style="background-color:#CA1551"/></picture></div></div></div></div><div class="col col-reset pc-block-base pc-block-base_reset-paddings pc-block-base_indentTop_0 pc-block-base_indentBottom_0 pc-constructor-block pc-constructor-block_type_blog-suggest-block"><section class="bc-wrapper bc-wrapper_padding-top_l bc-wrapper_padding-bottom_l"><div class="pc-SliderBlock"><div class="pc-title pc-SliderBlock__header pc-SliderBlock__header_no-description"><div class="col  col-12 col-sm-8 col-reset"><h2 class="pc-title-item pc-title-item_size_m pc-title-item_reset-margin" data-qa="undefined-header"><span class="pc-title-item__text">See also</span></h2></div></div><div class="pc-SliderBlock__animate-slides"><span style="font-size:0"></span><div><div class="slick-slider pc-slick-origin slick-initialized"><div class="slick-list"><div class="slick-track" style="width:100%;left:0%"><div data-index="0" class="slick-slide slick-active slick-current" tabindex="-1" aria-hidden="false" style="outline:none;width:33.333333333333336%"><div><div class="link" data-link-type="router"><a draggable="false" aria-labelledby="g-uniq-1224878" aria-describedby="g-uniq-1224879 g-uniq-1224880 g-uniq-1224882" class="g-link g-link_view_normal pc-card-base-block pc-card-base-block_border_shadow bc-post-card__card" href="../../../2023/07/unifying-real-time-data-processing-kafka-spark-and-clickhouse.html"><div class="pc-storage-background-image pc-card-base-block__header bc-post-card__header" data-qa="background-image"><picture data-qa="background-image-image"><source srcSet="../../../../../assets/blog/articles/unifying-real-time-data-processing-kafka-spark-and-clickhouse-cover.png.webp" type="image/webp" data-qa="background-image-image-desktop-source-compressed"/><img alt="" src="../../../../../assets/blog/articles/unifying-real-time-data-processing-kafka-spark-and-clickhouse-cover.png" class="pc-storage-background-image__img"/></picture><div class="pc-storage-background-image__container"><div class="pc-card-base-block__header-content"><div class="bc-post-card__image-container" data-qa="blog-suggest-header"></div></div></div></div><div class="pc-card-base-block__body"><div class="pc-card-base-block__content"><h3 class="bc-post-card__title bc-post-card__title_size_s"><span><span id="g-uniq-1224878">Unifying real-time data processing: Kafka, Spark, and ClickHouse</span></span></h3><span class="yfm yfm_blog_card bc-post-card__description" id="g-uniq-1224879">Written by: Amos Gutman, DoubleCloud Senior Solution Architect</span></div><div class="pc-card-base-block__footer"><div class="bc-post-info__container"><div class="bc-post-info__suggest-container"><div class="bc-post-info__item bc-post-info__item_size_s" id="g-uniq-1224880">July 17, 2023</div><div class="bc-post-info__item bc-post-info__item_size_s" id="g-uniq-1224882"><span class="bc-post-info__icon"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="16" height="16" class="g-icon bc-post-info__icon-color" fill="currentColor" stroke="none" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 17" fill="currentColor" aria-hidden="true"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 16.004a8 8 0 1 1 0-16 8 8 0 0 1 0 16Zm0-2a6 6 0 1 0 0-12 6 6 0 0 0 0 12Zm3.357-3.736a1 1 0 0 0-.342-1.372L9 7.688V5.004a1 1 0 0 0-2 0v3.25a1 1 0 0 0 .486.857l2.5 1.5a1 1 0 0 0 1.371-.343Z"></path></svg></svg></span>10 mins to read</div></div></div></div></div></a></div></div></div><div data-index="1" class="slick-slide slick-active" tabindex="-1" aria-hidden="false" style="outline:none;width:33.333333333333336%"><div><div class="link" data-link-type="router"><a draggable="false" aria-labelledby="g-uniq-1224883" aria-describedby="g-uniq-1224884 g-uniq-1224885 g-uniq-1224887" class="g-link g-link_view_normal pc-card-base-block pc-card-base-block_border_shadow bc-post-card__card" href="../../02/kafka-and-clickhouse-unlocking-the-power-duo.html"><div class="pc-storage-background-image pc-card-base-block__header bc-post-card__header" data-qa="background-image"><picture data-qa="background-image-image"><source srcSet="../../../../../assets/blog/articles/kafka-clickhouse-schema-cover.png.webp" type="image/webp" data-qa="background-image-image-desktop-source-compressed"/><img alt="" src="../../../../../assets/blog/articles/kafka-clickhouse-schema-cover.png" class="pc-storage-background-image__img"/></picture><div class="pc-storage-background-image__container"><div class="pc-card-base-block__header-content"><div class="bc-post-card__image-container" data-qa="blog-suggest-header"></div></div></div></div><div class="pc-card-base-block__body"><div class="pc-card-base-block__content"><h3 class="bc-post-card__title bc-post-card__title_size_s"><span><span id="g-uniq-1224883">Unlocking the power duo: Kafka and ClickHouse for lightning-fast data processing</span></span></h3><span class="yfm yfm_blog_card bc-post-card__description" id="g-uniq-1224884">Written by: Andrei Tserakhau, DoubleCloud Tech Lead</span></div><div class="pc-card-base-block__footer"><div class="bc-post-info__container"><div class="bc-post-info__suggest-container"><div class="bc-post-info__item bc-post-info__item_size_s" id="g-uniq-1224885">February 21, 2024</div><div class="bc-post-info__item bc-post-info__item_size_s" id="g-uniq-1224887"><span class="bc-post-info__icon"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="16" height="16" class="g-icon bc-post-info__icon-color" fill="currentColor" stroke="none" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 17" fill="currentColor" aria-hidden="true"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 16.004a8 8 0 1 1 0-16 8 8 0 0 1 0 16Zm0-2a6 6 0 1 0 0-12 6 6 0 0 0 0 12Zm3.357-3.736a1 1 0 0 0-.342-1.372L9 7.688V5.004a1 1 0 0 0-2 0v3.25a1 1 0 0 0 .486.857l2.5 1.5a1 1 0 0 0 1.371-.343Z"></path></svg></svg></span>15 mins to read</div></div></div></div></div></a></div></div></div><div data-index="2" class="slick-slide slick-active" tabindex="-1" aria-hidden="false" style="outline:none;width:33.333333333333336%"><div><div class="link" data-link-type="router"><a draggable="false" aria-labelledby="g-uniq-1224888" aria-describedby="g-uniq-1224889 g-uniq-1224890 g-uniq-1224892" class="g-link g-link_view_normal pc-card-base-block pc-card-base-block_border_shadow bc-post-card__card" href="../../07/7-essential-tips-for-a-production-clickhouse-cluster.html"><div class="pc-storage-background-image pc-card-base-block__header bc-post-card__header" data-qa="background-image"><picture data-qa="background-image-image"><source srcSet="../../../../../assets/blog/articles/2024/7-essential-tips-for-a-production-clickhouse-cluster-small-cover.png.webp" type="image/webp" data-qa="background-image-image-desktop-source-compressed"/><img alt="" src="../../../../../assets/blog/articles/2024/7-essential-tips-for-a-production-clickhouse-cluster-small-cover.png" class="pc-storage-background-image__img"/></picture><div class="pc-storage-background-image__container"><div class="pc-card-base-block__header-content"><div class="bc-post-card__image-container" data-qa="blog-suggest-header"></div></div></div></div><div class="pc-card-base-block__body"><div class="pc-card-base-block__content"><h3 class="bc-post-card__title bc-post-card__title_size_s"><span><span id="g-uniq-1224888">7 essential tips for a production ClickHouse cluster</span></span></h3><span class="yfm yfm_blog_card bc-post-card__description" id="g-uniq-1224889">Written by: Vladimir Ivoninskii</span></div><div class="pc-card-base-block__footer"><div class="bc-post-info__container"><div class="bc-post-info__suggest-container"><div class="bc-post-info__item bc-post-info__item_size_s" id="g-uniq-1224890">July 29, 2024</div><div class="bc-post-info__item bc-post-info__item_size_s" id="g-uniq-1224892"><span class="bc-post-info__icon"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="16" height="16" class="g-icon bc-post-info__icon-color" fill="currentColor" stroke="none" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 17" fill="currentColor" aria-hidden="true"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 16.004a8 8 0 1 1 0-16 8 8 0 0 1 0 16Zm0-2a6 6 0 1 0 0-12 6 6 0 0 0 0 12Zm3.357-3.736a1 1 0 0 0-.342-1.372L9 7.688V5.004a1 1 0 0 0-2 0v3.25a1 1 0 0 0 .486.857l2.5 1.5a1 1 0 0 0 1.371-.343Z"></path></svg></svg></span>10 mins to read</div></div></div></div></div></a></div></div></div></div></div></div><div class="pc-SliderBlock__footer"></div></div></div></div></section></div></div></div></div></div></main></div></div></div><div class="bc-prompt bc-prompt_close"><div class="bc-prompt__content"><span class="bc-prompt__text">Sign in to save this post</span><div class="bc-prompt__actions"><button class="g-button g-button_view_action g-button_size_l g-button_pin_round-round bc-prompt__action" type="button"><span class="g-button__text">Sign In</span></button></div></div></div></div><footer class="footer"><div class="pc-Grid"><div class="container-fluid "><div class="row"><div class="col  col-12 col-md-4 footer__column"><div class="link" data-link-type="router"><div class="logo footer__logo"><img alt="Logo Icon" src="../../../../../assets/logo/dc-logo-dark.svg" width="178" height="36" decoding="async" data-nimg="future" class="logo__icon" loading="lazy" style="color:transparent"/><span class="logo__text"></span></div></div><div class="pc-Grid subscription-form-block"><div class="container-fluid "><div class="row subscription-form-block__container"><div class="col  col-12"><span class="subscription-form-block__header">Subscribe to our newsletter</span></div><div class="col  col-12"><div class="pc-hubspot-form pc-hubspot-form_theme_light" id="hubspot-form-b9015518-c7ea-4173-a96b-a251994635e3"></div></div><div class="col  col-12"><span class="subscription-form-block__footer">By submitting this form, you agree to our <a href="../../../../../legal/privacy.html">Privacy policy</a></span></div></div></div></div></div><div class="col  col-6 col-sm-3 col-md-2 footer__column"><div class="footer__column-title">Products</div><a aria-label="Managed Service for ClickHouse®" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../services/managed-clickhouse.html"><div class="navigation-item"><span class="navigation-item__text">Managed Service for ClickHouse®</span></div></a><a aria-label="Managed Service for Apache Kafka®" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../services/managed-kafka.html"><div class="navigation-item"><span class="navigation-item__text">Managed Service for Apache Kafka®</span></div></a><a aria-label="Managed Service for Apache Airflow®" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../services/managed-airflow/index.html"><div class="navigation-item"><span class="navigation-item__text">Managed Service for Apache Airflow®</span></div></a><a aria-label="Data Transfer" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../services/doublecloud-transfer.html"><div class="navigation-item"><span class="navigation-item__text">Data Transfer</span></div></a><a aria-label="Data Visualization" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../services/doublecloud-visualization.html"><div class="navigation-item"><span class="navigation-item__text">Data Visualization</span></div></a></div><div class="col  col-6 col-sm-3 col-md-2 footer__column"><div class="footer__column-title">Solutions</div><a aria-label="Case studies" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../resources/case-studies/index.html"><div class="navigation-item"><span class="navigation-item__text">Case studies</span></div></a><a aria-label="Customer-facing analytics" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../customer-facing-analytics/index.html"><div class="navigation-item"><span class="navigation-item__text">Customer-facing analytics</span></div></a><a aria-label="Real-time analytics" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../solutions/real-time-analytics/index.html"><div class="navigation-item"><span class="navigation-item__text">Real-time analytics</span></div></a><a aria-label="Observability and monitoring" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../solutions/observability-and-monitoring/index.html"><div class="navigation-item"><span class="navigation-item__text">Observability and monitoring</span></div></a><a aria-label="AdTech and MarTech data analytics" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../solutions/adtech.html"><div class="navigation-item"><span class="navigation-item__text">AdTech and MarTech data analytics</span></div></a><a aria-label="Analytics for mobile and gaming Apps" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../solutions/web-mobile-gaming-apps.html"><div class="navigation-item"><span class="navigation-item__text">Analytics for mobile and gaming Apps</span></div></a><a aria-label="EdTech data analytics" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../solutions/edtech/index.html"><div class="navigation-item"><span class="navigation-item__text">EdTech data analytics</span></div></a><a aria-label="FinTech data analytics" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../solutions/fintech-real-time-analytics/index.html"><div class="navigation-item"><span class="navigation-item__text">FinTech data analytics</span></div></a></div><div class="col  col-6 col-sm-3 col-md-2 footer__column"><div class="footer__column-title">Resources</div><a aria-label="Documentation" class="navigation-item navigation-item_type_link footer__column-link" href="../../../../../docs/index.html"><div class="navigation-item"><span class="navigation-item__text">Documentation</span></div></a><a aria-label="Webinars" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../webinars/index.html"><div class="navigation-item"><span class="navigation-item__text">Webinars</span></div></a><a aria-label="Blog" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../index.html"><div class="navigation-item navigation-item_selected"><span class="navigation-item__text">Blog</span></div></a><a href="https://join.slack.com/t/double-cloud/shared_invite/zt-1pbz9lfte-5GoIX~8CmVYqmVQfRFPNdA" aria-label="Slack" class="navigation-item navigation-item_type_link footer__column-link" target="_blank" rel="noopener noreferrer"><div class="navigation-item"><span class="navigation-item__text">Slack</span></div></a><a aria-label="Support" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../support/index.html"><div class="navigation-item"><span class="navigation-item__text">Support</span></div></a><a href="https://status.double.cloud/" aria-label="Status updates" class="navigation-item navigation-item_type_link footer__column-link" target="_blank" rel="noopener noreferrer"><div class="navigation-item"><span class="navigation-item__text">Status updates</span></div></a><a aria-label="Product comparisons" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../comparison/index.html"><div class="navigation-item"><span class="navigation-item__text">Product comparisons</span></div></a><a aria-label="Site map" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../sitemap/index.html"><div class="navigation-item"><span class="navigation-item__text">Site map</span></div></a></div><div class="col  col-6 col-sm-3 col-md-2 footer__column"><div class="footer__column-title">Company</div><a aria-label="About DoubleCloud" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../company/about-us.html"><div class="navigation-item"><span class="navigation-item__text">About DoubleCloud</span></div></a><a aria-label="Careers" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../company/careers.html"><div class="navigation-item"><span class="navigation-item__text">Careers</span></div></a><a aria-label="AWS Partnership" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../aws-partnership/index.html"><div class="navigation-item"><span class="navigation-item__text">AWS Partnership</span></div></a><a aria-label="Contact us" class="navigation-item navigation-item_type_link footer__column-link" data-link-type="router" href="../../../../../company/contact-us.html"><div class="navigation-item"><span class="navigation-item__text">Contact us</span></div></a></div></div><div class="row"><div class="col  col-12 footer__underline"><div class="footer__underline-links"><a href="../../../../../legal/customer_agreement/index.html" aria-label="Customer Agreement" class="navigation-item navigation-item_type_link footer__underline-link" target="_blank"><div class="navigation-item"><span class="navigation-item__text">Customer Agreement</span></div></a><a href="../../../../../legal/privacy.html" aria-label="Privacy Policy" class="navigation-item navigation-item_type_link footer__underline-link" target="_blank"><div class="navigation-item"><span class="navigation-item__text">Privacy Policy</span></div></a><a aria-label="Pricing" class="navigation-item navigation-item_type_link footer__underline-link" data-link-type="router" href="../../../../../pricing.html"><div class="navigation-item"><span class="navigation-item__text">Pricing</span></div></a><a href="../../../../../security.html" aria-label="Security" class="navigation-item navigation-item_type_link footer__underline-link" target="_blank"><div class="navigation-item"><span class="navigation-item__text">Security</span></div></a></div><div class="footer__underline-copyright">© 2024 DoubleCloud</div></div></div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json" nonce="zQcdnLrPwtUu1QPPXR/ORA==">{"props":{"pageProps":{"data":{"status":"fulfilled","pageContent":{"page":{"id":168,"name":"blog/posts/2024/09/real-time-analytics-kafka-clickhouse-integration","createdAt":"2024-09-11T15:58:07.226Z","updatedAt":"2024-09-11T15:58:07.226Z","type":"default","isDeleted":false,"versionOnTranslationId":null,"pageId":168,"locale":"en","publishedVersionId":2296,"lastVersionId":2296,"content":{"blocks":[{"type":"blog-header-block","resetPaddings":true,"paddingBottom":"l","width":"s","verticalOffset":"l","background":{"image":{"src":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-cover.png","disableCompress":true,"fetchPriority":"high"},"color":"#000000","fullWidth":false}},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"right","resetPaddings":true,"text":"\u003cp\u003eQuick navigation:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#intro\"\u003eIntro\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#data-solution-overview\"\u003eData Solution overview\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#problem-outline\"\u003eProblem outline\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sample-event\"\u003eSample event\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#setup-infrastructure\"\u003eSetup Infrastructure\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#setup-transfer-endpoints\"\u003eSetup transfer endpoints\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#creating-and-activating-the-transfer\"\u003eCreating and activating the Transfer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#producer-script\"\u003eProducer script\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sanity-checks-to-ensure-everything-works-as-expected\"\u003eSanity checks to\u0026nbsp;ensure everything works as\u0026nbsp;expected\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#adding-transformation\"\u003eAdding transformation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#check-the-final-result\"\u003eCheck the final result\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#wrap-up\"\u003eWrap up\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e"},{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003ch2 id=\"intro\"\u003e\u003ca href=\"#intro\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eIntro\u003c/span\u003e\u003c/a\u003eIntro\u003c/h2\u003e\n\u003cp\u003eWelcome to\u0026nbsp;this series of\u0026nbsp;posts exploring a\u0026nbsp;real-time analytics use case. The series covers various aspects of\u0026nbsp;setting up\u0026nbsp;a\u0026nbsp;real-time analytics platform using DoubleCloud managed services, from data ingestion to\u0026nbsp;aggregation computation, and finally, to\u0026nbsp;dashboards based on\u0026nbsp;those data marts.\u003c/p\u003e\n\u003cp\u003eThis first post focuses on\u0026nbsp;the initial setup and data loading using ClickHouse, Apache Kafka, and DoubleCloud\u0026rsquo;s Data Transfer.\u003c/p\u003e\n\u003ch2 id=\"data-solution-overview\"\u003e\u003ca href=\"#data-solution-overview\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eData Solution overview\u003c/span\u003e\u003c/a\u003eData Solution overview\u003c/h2\u003e\n\u003cp\u003eBy\u0026nbsp;the end of\u0026nbsp;the series, we\u0026nbsp;will have built a\u0026nbsp;setup that enables us\u0026nbsp;to\u0026nbsp;ingest and make decisions based on\u0026nbsp;clickstream data. The overall architecture of\u0026nbsp;our data platform looks like this schematically:\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-1-2.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eIn\u0026nbsp;the diagram, the white part represents an\u0026nbsp;external data provider (such as\u0026nbsp;a\u0026nbsp;web performance monitoring tool), while everything else consists of\u0026nbsp;DoubleCloud managed services. We\u0026nbsp;will use a\u0026nbsp;simple Python script to\u0026nbsp;send data. This first part focuses on\u0026nbsp;data ingestion, the initial setup of\u0026nbsp;our Kafka server, and the data loading process for ClickHouse:\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-2-2.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eThe upcoming parts of\u0026nbsp;the series will focus on\u0026nbsp;aggregations and visualization. While we\u0026nbsp;will address performance when relevant, the primary goal of\u0026nbsp;the series is\u0026nbsp;to\u0026nbsp;describe connecting the various components together.\u003c/p\u003e\n\u003ch2 id=\"problem-outline\"\u003e\u003ca href=\"#problem-outline\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eProblem outline\u003c/span\u003e\u003c/a\u003eProblem outline\u003c/h2\u003e\n\u003cp\u003eOne of\u0026nbsp;the common tasks in\u0026nbsp;real-time analytics is\u0026nbsp;performing aggregations. We\u0026nbsp;have clickstream data and want to\u0026nbsp;visualize some basic metrics related to\u0026nbsp;user activity on\u0026nbsp;the website. In\u0026nbsp;this example, which will be\u0026nbsp;used throughout the entire series, we\u0026nbsp;will use a\u0026nbsp;subset of\u0026nbsp;fields from our clickstream data to\u0026nbsp;calculate how many products were purchased during specific hours of\u0026nbsp;the day.\u003c/p\u003e\n\u003ch2 id=\"sample-event\"\u003e\u003ca href=\"#sample-event\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eSample event\u003c/span\u003e\u003c/a\u003eSample event\u003c/h2\u003e\n\u003cp\u003eHere\u0026rsquo;s an\u0026nbsp;example event from our data source, representing user interactions with products in\u0026nbsp;a\u0026nbsp;marketplace. This event is\u0026nbsp;already enriched with additional information about the user and the item they interacted with:\u003c/p\u003e\n\n    \u003cdiv class=\"yfm-clipboard\"\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs json\"\u003e\u003cspan class=\"hljs-punctuation\"\u003e{\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"basket_price\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"detectedCorruption\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003e\u003cspan class=\"hljs-keyword\"\u003efalse\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"detectedDuplicate\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003e\u003cspan class=\"hljs-keyword\"\u003efalse\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"eventType\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"itemViewEvent\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"firstInSession\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003e\u003cspan class=\"hljs-keyword\"\u003etrue\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"item_id\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"bx_VHZvTOyk_CYNTZGlxyopNGYodgtybLKqToopjOqbT\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"item_price\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e4876\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"item_url\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"https://mu3bxs.webshop24.eu/katalog/item/t-shirt-female-temptation/\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"location\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"https://mu3bxs.webshop24.eu/\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"pageViewId\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"0:qawVTkAI:IyqIWWkimHqgvBGCbeMMIoosmXiuLcvW\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"partyId\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"0:ckQoIhoa:PtdjtCnxGtRzfXvovHcDtltPSaDzpvxM\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"referer\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"https://mu3bxs.webshop24.eu//katalog/item/slippers-pink-paradise/\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"remoteHost\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"test0\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"sessionId\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"0:ZSMAmydy:yqxDDTWQfbRtrauPYAAIGQsCVubHrdov\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"timestamp\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e1545127200000\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"userAgentName\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36\"\u003c/span\u003e\n\u003cspan class=\"hljs-punctuation\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\n    \u003csvg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" class=\"yfm-clipboard-button\" data-animation=\"15\"\u003e\n        \u003cpath fill=\"currentColor\" d=\"M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z\"\u003e\u003c/path\u003e\n        \u003cpath stroke=\"currentColor\" fill=\"transparent\" stroke-width=\"1.5\" d=\"M9.5 13l3 3l5 -5\" visibility=\"hidden\"\u003e\n            \u003canimate id=\"visibileAnimation-15\" attributeName=\"visibility\" from=\"hidden\" to=\"visible\" dur=\"0.2s\" fill=\"freeze\" begin\u003e\u003c/animate\u003e\n            \u003canimate id=\"hideAnimation-15\" attributeName=\"visibility\" from=\"visible\" to=\"hidden\" dur=\"1s\" begin=\"visibileAnimation-15.end+1\" fill=\"freeze\"\u003e\u003c/animate\u003e\n        \u003c/path\u003e\n    \u003c/svg\u003e\n    \u003c/div\u003e\n\u003cp\u003eFor the purpose of\u0026nbsp;our example pipeline, we\u0026nbsp;will concentrate on\u0026nbsp;a\u0026nbsp;subset of\u0026nbsp;the event\u0026rsquo;s fields and set our ingestion pipeline to\u0026nbsp;use only the ones we\u0026rsquo;re interested\u0026nbsp;in. To\u0026nbsp;compute aggregated statistics, we\u0026nbsp;will need the following fields:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003epartyId\u003c/code\u003e (string key, denoting global userId)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003esessionId\u003c/code\u003e (string key, used to\u0026nbsp;mark the same user session)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eitem_price\u003c/code\u003e (integer representing the price of\u0026nbsp;an\u0026nbsp;item)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eeventType\u003c/code\u003e (string field for the type of\u0026nbsp;event)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003edetectedDuplicate\u003c/code\u003e and \u003ccode\u003edetectedCorruption\u003c/code\u003e (boolean fields from upcoming data enrichment systems that will be\u0026nbsp;used to\u0026nbsp;filter data)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEverything else is\u0026nbsp;unnecessary for our example use case, but it\u0026rsquo;s helpful to\u0026nbsp;know what those fields are in\u0026nbsp;case there is\u0026nbsp;a\u0026nbsp;need for further analysis later.\u003c/p\u003e\n\u003cp\u003eThe Python code, along with sample data and instructions on\u0026nbsp;how to\u0026nbsp;run it, can be\u0026nbsp;found \u003ca href=\"https://github.com/doublecloud/showcase-webshop-clickstream-aggregation\"\u003ein\u0026nbsp;this repository\u003c/a\u003e.\u003c/p\u003e"}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"background-card","column":"right","background":{"src":"/assets/doublecloud/cards/card-service-kafka-v3.png"},"paddingBottom":"l","title":"Managed Service for Apache Kafka","text":"\u003cp\u003eFully managed, secure, and highly available service for distributed delivery, storage, and real-time data processing.\u003c/p\u003e","buttons":[{"text":"Learn more","theme":"action","url":"/services/managed-kafka/"}]},{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003ch2 id=\"setup-infrastructure\"\u003e\u003ca href=\"#setup-infrastructure\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eSetup infrastructure\u003c/span\u003e\u003c/a\u003eSetup infrastructure\u003c/h2\u003e\n\u003ch3 id=\"kafka-cluster\"\u003e\u003ca href=\"#kafka-cluster\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eKafka cluster\u003c/span\u003e\u003c/a\u003eKafka cluster\u003c/h3\u003e\n\u003cp\u003eWe\u0026nbsp;will use Kafka as\u0026nbsp;our ingestion layer. For the purposes of\u0026nbsp;this series, we\u0026nbsp;can go\u0026nbsp;with the default options: select the eu-central-1 zone and choose the smallest possible configuration. The only change I\u0026nbsp;would personally recommend is\u0026nbsp;opting for an\u0026nbsp;ARM architecture, as\u0026nbsp;it\u0026nbsp;tends to\u0026nbsp;perform slightly better, as\u0026nbsp;highlighted in\u0026nbsp;our article on\u0026nbsp;this topic: \u003ca href=\"https://double.cloud/blog/posts/2024/06/benchmarking-apache-kafka-performance-per-price/\"\u003eBenchmarking Apache Kafka: performance per price\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSimply pick a\u0026nbsp;cluster name you\u0026rsquo;re comfortable with, select a\u0026nbsp;recent Kafka version (3.5), and you\u0026rsquo;re all set!\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-3.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eProvisioning should take a\u0026nbsp;few minutes (we\u0026nbsp;can create the ClickHouse cluster in\u0026nbsp;the meantime). Once the cluster is\u0026nbsp;up\u0026nbsp;and running, let\u0026rsquo;s navigate to\u0026nbsp;cluster settings and create a\u0026nbsp;topic for our events.\u003c/p\u003e\n\u003ch4 id=\"kafka-topic-for-incoming-messages\"\u003e\u003ca href=\"#kafka-topic-for-incoming-messages\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eKafka topic for incoming messages\u003c/span\u003e\u003c/a\u003eKafka topic for incoming messages\u003c/h4\u003e\n\u003cp\u003eWe\u0026nbsp;will be\u0026nbsp;using a\u0026nbsp;standard architectural pattern of\u0026nbsp;having a\u0026nbsp;single topic per schema, meaning that each different schema of\u0026nbsp;messages will be\u0026nbsp;assigned to\u0026nbsp;a\u0026nbsp;separate topic. Therefore, we\u0026nbsp;need to\u0026nbsp;create a\u0026nbsp;topic for incoming messages, which can be\u0026nbsp;done through the same cluster control interface.\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-4.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eFor the purpose of\u0026nbsp;this tutorial, our load is\u0026nbsp;non-threatening, so\u0026nbsp;we\u0026nbsp;can use a\u0026nbsp;simple topic with just one partition and a\u0026nbsp;replication factor of\u0026nbsp;one.\u003c/p\u003e\n\u003ch4 id=\"allowlist-caveat\"\u003e\u003ca href=\"#allowlist-caveat\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eAllowList caveat\u003c/span\u003e\u003c/a\u003eAllowList caveat\u003c/h4\u003e\n\u003cp\u003eTo\u0026nbsp;simplify testing, DoubleCloud adds your IP\u0026nbsp;address to\u0026nbsp;the \u003cstrong\u003eALLOW LIST\u003c/strong\u003e in\u0026nbsp;the cluster settings. Keep this in\u0026nbsp;mind if\u0026nbsp;you frequently switch Wi-Fi networks while working from your laptop.\u003c/p\u003e"}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"background-card","column":"right","background":{"src":"/assets/doublecloud/cards/card-service-clickhouse-v3.png"},"paddingBottom":"l","title":"Managed Service for ClickHouse","text":"\u003cp\u003eFully managed service from the creators of\u0026nbsp;the world\u0026rsquo;s 1st managed ClickHouse. Backups, 24/7 monitoring, auto-scaling, and updates.\u003c/p\u003e","buttons":[{"text":"Learn more","theme":"action","url":"/services/managed-clickhouse/"}]},{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003ch3 id=\"clickhouse-cluster\"\u003e\u003ca href=\"#clickhouse-cluster\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eClickHouse cluster\u003c/span\u003e\u003c/a\u003eClickHouse cluster\u003c/h3\u003e\n\u003cp\u003eFor the ClickHouse cluster, let\u0026rsquo;s select the same availability zone and opt for the smallest possible setup: 1\u0026nbsp;replica and 1\u0026nbsp;shard, resulting in\u0026nbsp;a\u0026nbsp;single ARM node with just 32\u0026nbsp;GB\u0026nbsp;of\u0026nbsp;storage. While you would typically want a\u0026nbsp;more robust configuration for production, these defaults are sufficient for our current needs. We\u0026rsquo;ll discuss scaling a\u0026nbsp;bit in\u0026nbsp;future parts of\u0026nbsp;this series.\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-5.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eChoose a\u0026nbsp;reasonable name for the cluster and select a\u0026nbsp;relevant version. The cluster creation UI\u0026nbsp;defaults to\u0026nbsp;the latest LTS version, but there\u0026rsquo;s nothing stopping us\u0026nbsp;from opting for a\u0026nbsp;more recent one.\u003c/p\u003e\n\u003ch4 id=\"clickhouse-database\"\u003e\u003ca href=\"#clickhouse-database\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eClickHouse database\u003c/span\u003e\u003c/a\u003eClickHouse database\u003c/h4\u003e\n\u003cp\u003eWhile we\u0026nbsp;can use the default database for ClickHouse, it\u0026nbsp;makes sense to\u0026nbsp;create a\u0026nbsp;different one for our application. Let\u0026rsquo;s go\u0026nbsp;ahead and do\u0026nbsp;that. There are multiple ways to\u0026nbsp;access our cluster, but the easiest method is\u0026nbsp;to\u0026nbsp;use the WebSQL interface. From the cluster interface, click on\u0026nbsp;the \u003cstrong\u003eWebSQL\u003c/strong\u003e button to\u0026nbsp;open the interface in\u0026nbsp;the new tab.\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-6.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eThis will automatically connect to\u0026nbsp;the cluster and authorize with admin credentials. Clicking on\u0026nbsp;any entity in\u0026nbsp;the left tree menu will open the query editor. Execute the following code to\u0026nbsp;create a\u0026nbsp;new database:\u003c/p\u003e\n\n    \u003cdiv class=\"yfm-clipboard\"\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs sql\"\u003e\u003cspan class=\"hljs-keyword\"\u003eCREATE\u003c/span\u003e DATABASE webshop;\n\u003c/code\u003e\u003c/pre\u003e\n\n    \u003csvg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" class=\"yfm-clipboard-button\" data-animation=\"3\"\u003e\n        \u003cpath fill=\"currentColor\" d=\"M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z\"\u003e\u003c/path\u003e\n        \u003cpath stroke=\"currentColor\" fill=\"transparent\" stroke-width=\"1.5\" d=\"M9.5 13l3 3l5 -5\" visibility=\"hidden\"\u003e\n            \u003canimate id=\"visibileAnimation-3\" attributeName=\"visibility\" from=\"hidden\" to=\"visible\" dur=\"0.2s\" fill=\"freeze\" begin\u003e\u003c/animate\u003e\n            \u003canimate id=\"hideAnimation-3\" attributeName=\"visibility\" from=\"visible\" to=\"hidden\" dur=\"1s\" begin=\"visibileAnimation-3.end+1\" fill=\"freeze\"\u003e\u003c/animate\u003e\n        \u003c/path\u003e\n    \u003c/svg\u003e\n    \u003c/div\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-7.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eI\u0026nbsp;suggest naming the new database \u003cstrong\u003ewebshop\u003c/strong\u003e, and I\u0026nbsp;will use this name in\u0026nbsp;the examples moving forward. Now that we\u0026nbsp;have our source and destination set up, let\u0026rsquo;s create a\u0026nbsp;\u003cstrong\u003eData Transfer\u003c/strong\u003e pipeline to\u0026nbsp;connect them.\u003c/p\u003e\n\u003ch4 id=\"allowlist-caveat\"\u003e\u003ca href=\"#allowlist-caveat\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eAllowList caveat\u003c/span\u003e\u003c/a\u003eAllowList caveat\u003c/h4\u003e\n\u003cp\u003eSimilar to\u0026nbsp;the Kafka cluster, DoubleCloud adds your IP\u0026nbsp;address to\u0026nbsp;the \u003cstrong\u003eALLOW LIST\u003c/strong\u003e in\u0026nbsp;the cluster settings behind the scenes. Keep this in\u0026nbsp;mind if\u0026nbsp;you frequently switch Wi-Fi networks while working from your laptop. It\u0026nbsp;is\u0026nbsp;advised not to\u0026nbsp;open your cluster to\u0026nbsp;the world carelessly, even for short-term testing purposes.\u003c/p\u003e\n\u003ch2 id=\"setup-transfer-endpoints\"\u003e\u003ca href=\"#setup-transfer-endpoints\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eSetup transfer endpoints\u003c/span\u003e\u003c/a\u003eSetup transfer endpoints\u003c/h2\u003e\n\u003cp\u003eDoubleCloud provides a\u0026nbsp;convenient way to\u0026nbsp;ingest data from Kafka to\u0026nbsp;ClickHouse through a\u0026nbsp;tool called \u003ca href=\"https://double.cloud/services/doublecloud-transfer/\"\u003eData Transfer\u003c/a\u003e. We\u0026nbsp;will use \u003cstrong\u003eTransfer\u003c/strong\u003e to\u0026nbsp;read data from our \u003cstrong\u003eKafka topic\u003c/strong\u003e (referred to\u0026nbsp;as\u0026nbsp;the source endpoint in\u0026nbsp;Transfer\u0026rsquo;s terminology) and publish it\u0026nbsp;to\u0026nbsp;\u003cstrong\u003eClickHouse\u003c/strong\u003e (the target endpoint in\u0026nbsp;Transfer\u0026rsquo;s terminology). Let\u0026rsquo;s set it\u0026nbsp;up!\u003c/p\u003e\n\u003ch3 id=\"kafka-transport-source-endpoint\"\u003e\u003ca href=\"#kafka-transport-source-endpoint\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eKafka: Transport source endpoint\u003c/span\u003e\u003c/a\u003eKafka: Transport source endpoint\u003c/h3\u003e\n\u003cp\u003eNavigate to\u0026nbsp;the \u003cstrong\u003eTransfer\u003c/strong\u003e page, switch to\u0026nbsp;the \u003cstrong\u003eEndpoint\u003c/strong\u003e tab, and create a\u0026nbsp;source endpoint. Select \u003cstrong\u003eKafka\u003c/strong\u003e as\u0026nbsp;the source type in\u0026nbsp;the dropdown and give it\u0026nbsp;a\u0026nbsp;reasonable name (this name will be\u0026nbsp;used internally by\u0026nbsp;Transfer).\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-8.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eSelect the recently created Kafka cluster and use the credentials to\u0026nbsp;connect to\u0026nbsp;it\u0026nbsp;via SASL. To\u0026nbsp;make the endpoint functional, add the topic that was created earlier.\u003c/p\u003e\n\u003ch4 id=\"json-fields\"\u003e\u003ca href=\"#json-fields\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eJSON fields\u003c/span\u003e\u003c/a\u003eJSON fields\u003c/h4\u003e\n\u003cp\u003eSince the initial analysis of\u0026nbsp;event data showed that we\u0026nbsp;don\u0026rsquo;t need all the fields, we\u0026nbsp;can include only the ones we\u0026nbsp;are interested\u0026nbsp;in. This can be\u0026nbsp;done using the \u003cstrong\u003eAdvanced settings\u003c/strong\u003e tab, where we\u0026nbsp;can specify a\u0026nbsp;JSON conversion rule with a\u0026nbsp;list of\u0026nbsp;relevant fields. Here\u0026rsquo;s what I\u0026nbsp;ended up\u0026nbsp;with:\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-9.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eAdditionally, since I\u0026nbsp;might be\u0026nbsp;interested in\u0026nbsp;other fields later, I\u0026rsquo;ll make sure that a\u0026nbsp;corresponding option is\u0026nbsp;enabled, just in\u0026nbsp;case.\u003c/p\u003e\n\u003ch3 id=\"clickhouse-transport-target-endpoint\"\u003e\u003ca href=\"#clickhouse-transport-target-endpoint\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eClickHouse: Transport target endpoint\u003c/span\u003e\u003c/a\u003eClickHouse: Transport target endpoint\u003c/h3\u003e\n\u003cp\u003eCreating the target endpoint is\u0026nbsp;straightforward as\u0026nbsp;well. There\u0026rsquo;s no\u0026nbsp;need for any additional setup; simply select the connection type, choose the correct cluster from the dropdown menu, and specify the target database (schema).\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-10.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eNow that both endpoints are set up, we\u0026nbsp;need to\u0026nbsp;create the transfer itself.\u003c/p\u003e\n\u003ch2 id=\"creating-and-activating-the-transfer\"\u003e\u003ca href=\"#creating-and-activating-the-transfer\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eCreating and activating the Transfer\u003c/span\u003e\u003c/a\u003eCreating and activating the Transfer\u003c/h2\u003e\n\u003cp\u003eWe\u0026nbsp;need to\u0026nbsp;specify the created endpoints, choose a\u0026nbsp;name, and that\u0026rsquo;s\u0026nbsp;it. Everything else can be\u0026nbsp;left at\u0026nbsp;the default settings. Click \u003cstrong\u003e\u0026ldquo;Submit\u0026rdquo;\u003c/strong\u003e and grab a\u0026nbsp;cup of\u0026nbsp;tea while the transfer is\u0026nbsp;being created.\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-11.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eOnce the transfer is\u0026nbsp;created, we\u0026nbsp;need to\u0026nbsp;activate it\u0026nbsp;and ensure it\u0026nbsp;is\u0026nbsp;running (its status should change accordingly).\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-12.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003ch2 id=\"producer-script\"\u003e\u003ca href=\"#producer-script\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eProducer script\u003c/span\u003e\u003c/a\u003eProducer script\u003c/h2\u003e\n\u003cp\u003eTo\u0026nbsp;test the pipeline, we\u0026nbsp;will be\u0026nbsp;producing 1,000 events from a\u0026nbsp;file using a\u0026nbsp;Python script. \u003ca href=\"https://github.com/doublecloud/showcase-webshop-clickstream-aggregation\"\u003eYou can check the source here\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eTo\u0026nbsp;run the script, install the required packages, set the environment variables for cluster access, and execute the following command in\u0026nbsp;the terminal:\u003c/p\u003e\n\n    \u003cdiv class=\"yfm-clipboard\"\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs python\"\u003eclickstream/produce_events.py\n\u003c/code\u003e\u003c/pre\u003e\n\n    \u003csvg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" class=\"yfm-clipboard-button\" data-animation=\"9\"\u003e\n        \u003cpath fill=\"currentColor\" d=\"M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z\"\u003e\u003c/path\u003e\n        \u003cpath stroke=\"currentColor\" fill=\"transparent\" stroke-width=\"1.5\" d=\"M9.5 13l3 3l5 -5\" visibility=\"hidden\"\u003e\n            \u003canimate id=\"visibileAnimation-9\" attributeName=\"visibility\" from=\"hidden\" to=\"visible\" dur=\"0.2s\" fill=\"freeze\" begin\u003e\u003c/animate\u003e\n            \u003canimate id=\"hideAnimation-9\" attributeName=\"visibility\" from=\"visible\" to=\"hidden\" dur=\"1s\" begin=\"visibileAnimation-9.end+1\" fill=\"freeze\"\u003e\u003c/animate\u003e\n        \u003c/path\u003e\n    \u003c/svg\u003e\n    \u003c/div\u003e\n\u003cp\u003eThis will produce 1,000 events from the file \u003cstrong\u003eevents1000.jsonl\u003c/strong\u003e. Refer to\u0026nbsp;the \u003ccode\u003eREADME\u003c/code\u003e if\u0026nbsp;you want to\u0026nbsp;customize something, encounter any issues or\u0026nbsp;if\u0026nbsp;you want to\u0026nbsp;manipulate the data first, such as\u0026nbsp;moving it\u0026nbsp;in\u0026nbsp;time if\u0026nbsp;needed.\u003c/p\u003e\n\u003ch2 id=\"sanity-checks-to-ensure-everything-works-as-expected\"\u003e\u003ca href=\"#sanity-checks-to-ensure-everything-works-as-expected\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eSanity checks to\u0026nbsp;ensure everything works as\u0026nbsp;expected\u003c/span\u003e\u003c/a\u003eSanity checks to\u0026nbsp;ensure everything works as\u0026nbsp;expected\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s perform some queries from the WebSQL interface to\u0026nbsp;check our data. If\u0026nbsp;we\u0026nbsp;open WebSQL Query editor, we\u0026nbsp;can see that all 1,000 events have arrived:\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-13.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eThe next logical step is\u0026nbsp;to\u0026nbsp;verify that the timestamps are in\u0026nbsp;the expected format:\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-14.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eIt\u0026nbsp;appears that the dates are slightly too futuristic. A\u0026nbsp;common issue with numeric timestamps from different systems is\u0026nbsp;that they might use different time formats. For example, one system might use microseconds while another uses seconds. Let\u0026rsquo;s see if\u0026nbsp;dividing the timestamp resolves the issue:\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-15.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eAnd indeed, it\u0026nbsp;does! We\u0026nbsp;now have two options:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAccount for the fact that our timestamps need special treatment before proceeding with the analysis.\u003c/li\u003e\n\u003cli\u003eTransform the timestamps upon ingestion.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTypical data modeling approach is\u0026nbsp;to\u0026nbsp;choose the first option, where you don\u0026rsquo;t modify data at\u0026nbsp;the ingestion \u003cstrong\u003e\u0026ldquo;source\u0026rdquo;\u003c/strong\u003e level and instead perform preparation in\u0026nbsp;the next stage.\u003c/p\u003e\n\u003cp\u003eHowever, in\u0026nbsp;modern data pipelines, it\u0026nbsp;is\u0026nbsp;generally acceptable to\u0026nbsp;perform simple transformations during ingestion, as\u0026nbsp;long as\u0026nbsp;they are indeed straightforward. Thankfully, Transfer is\u0026nbsp;capable of\u0026nbsp;doing just that!\u003c/p\u003e\n\u003ch2 id=\"adding-transformation\"\u003e\u003ca href=\"#adding-transformation\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eAdding transformation\u003c/span\u003e\u003c/a\u003eAdding transformation\u003c/h2\u003e\n\u003cp\u003eIf\u0026nbsp;we\u0026nbsp;go\u0026nbsp;back to\u0026nbsp;our transfer and open \u003cstrong\u003eEdit\u003c/strong\u003e view, we\u0026rsquo;ll find a\u0026nbsp;button labeled \u003cstrong\u003e\u0026ldquo;Transformation\u0026rdquo;\u003c/strong\u003e towards the end of\u0026nbsp;the page:\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-16.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eThis humble little feature is\u0026nbsp;exactly what we\u0026nbsp;need for our transformation. Transfer supports multiple ways to\u0026nbsp;adjust your data as\u0026nbsp;it\u0026nbsp;moves between endpoints. We\u0026nbsp;will use the on-the-fly SQL processor. Click on\u0026nbsp;the button and select \u003cstrong\u003e\u0026ldquo;SQL\u0026rdquo;\u003c/strong\u003e from the Transformer dropdown. I\u0026rsquo;ll create a\u0026nbsp;new field called \u003cstrong\u003e\u0026ldquo;my_ts\u0026rdquo;\u003c/strong\u003e that will hold the original timestamp divided by\u0026nbsp;1,000:\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-17.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003cp\u003eBy\u0026nbsp;the way, Transfer allows you to\u0026nbsp;stack multiple transformations in\u0026nbsp;a\u0026nbsp;chain of\u0026nbsp;operations if\u0026nbsp;you wish. However, there are some limitations to\u0026nbsp;what is\u0026nbsp;possible and, more importantly, what should be\u0026nbsp;done at\u0026nbsp;this step. Keep in\u0026nbsp;mind that these operations are effectively hidden from your view, so\u0026nbsp;you should avoid extensive data transformations here and instead leave that to\u0026nbsp;your ETL processes in\u0026nbsp;the next stage of\u0026nbsp;the data processing pipeline.\u003c/p\u003e\n\u003ch2 id=\"check-the-final-result\"\u003e\u003ca href=\"#check-the-final-result\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eCheck the final result\u003c/span\u003e\u003c/a\u003eCheck the final result\u003c/h2\u003e\n\u003cp\u003eUpdate the transfer, drop the table (since we\u0026nbsp;are altering the scheme, this is\u0026nbsp;the easiest way to\u0026nbsp;update it), produce new data, and voil\u0026agrave;! We\u0026nbsp;have our timestamp in\u0026nbsp;expected format and within the correct century.\u003c/p\u003e"},{"type":"blog-media-block","column":"left","resetPaddings":true,"text":"","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-18.png","fullWidth":false}]},{"type":"blog-layout-block","resetPaddings":true,"mobileOrder":"reverse","children":[{"type":"blog-yfm-block","column":"left","resetPaddings":true,"text":"\u003ch2 id=\"wrap-up\"\u003e\u003ca href=\"#wrap-up\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eWrap up\u003c/span\u003e\u003c/a\u003eWrap up\u003c/h2\u003e\n\u003cp\u003eIn\u0026nbsp;just a\u0026nbsp;few clicks, we\u0026nbsp;have created a\u0026nbsp;Kafka cluster, a\u0026nbsp;ClickHouse cluster, and a\u0026nbsp;Transfer pipeline with on-the-fly data transformation that now ingests incoming data in\u0026nbsp;our database. We\u0026nbsp;have everything ready to\u0026nbsp;start computing aggregates, which we\u0026nbsp;will cover in\u0026nbsp;the next part. Stay tuned for Part II!\u003c/p\u003e\n\u003cp\u003eIf\u0026nbsp;you have any questions or\u0026nbsp;would like to\u0026nbsp;discuss this series further, feel free to\u0026nbsp;\u003ca href=\"https://join.slack.com/t/double-cloud/shared_invite/zt-1pbz9lfte-5GoIX~8CmVYqmVQfRFPNdA\"\u003ereach out on\u0026nbsp;Slack\u003c/a\u003e.\u003c/p\u003e"}]},{"type":"content-layout-block","background":{"src":"/assets/doublecloud/doublecloud-cover-5.png","style":{"backgroundColor":"#CA1551"}},"centered":true,"textContent":{"title":"Get started with DoubleCloud","buttons":[{"text":"Start free trial","size":"promo","theme":"accent","url":"https://auth.double.cloud/s/signup"},{"text":"Contact us","theme":"pseudo","url":"#contact-us-form"}]}},{"type":"blog-suggest-block","resetPaddings":true,"fullWidth":false}]},"title":"Clickstream analytics case study. Part I: Kafka -\u003e Data Transfer -\u003e ClickHouse","noIndex":false,"shareTitle":"Clickstream analytics case study. Part I: Kafka -\u003e Data Transfer -\u003e ClickHouse","shareDescription":"How to set up a real-time analytics pipeline using Kafka and ClickHouse: initial setup and data loading.","shareImage":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-sharing.png","pageLocaleId":336,"author":"unknown","metaDescription":"How to set up a real-time analytics pipeline using Kafka and ClickHouse: initial setup and data loading.","keywords":[],"shareGenTitle":null,"canonicalLink":null,"sharingType":"custom","sharingTheme":"light","comment":".","shareImageUrl":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-sharing.png","pageRegionId":null,"service":null,"solution":null,"locales":[{"locale":"ru","publishedVersionId":null},{"locale":"en","publishedVersionId":2296}],"regions":[],"pageRegions":[{"id":7,"pageId":168,"regionCode":"en","createdAt":"2024-09-06T13:02:47.826Z","updatedAt":"2024-09-06T13:02:47.856Z","publishedVersionId":null,"lastVersionId":2288}]},"post":{"url":"","id":168,"name":"real-time-analytics-kafka-clickhouse-integration","isPinned":false,"blogPostId":168,"image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-small-cover.png","readingTime":15,"date":"2024-09-06T00:00:00Z","likes":0,"hasUserLike":false,"services":[],"slug":"","authors":[],"locale":{"lang":"en"},"textTitle":"Clickstream analytics case study. Part I: Kafka → Data Transfer → ClickHouse","htmlTitle":"Clickstream analytics case study. Part I: Kafka -\u0026gt; Data Transfer -\u0026gt; ClickHouse","title":"Clickstream analytics case study. Part I: Kafka -\u003e Data Transfer -\u003e ClickHouse","tags":[{"icon":null,"slug":"insights","name":"Insights","createdAt":"","updatedAt":"","count":0},{"icon":null,"slug":"ClickHouse","name":"ClickHouse","createdAt":"","updatedAt":"","count":0},{"icon":null,"slug":"kafka","name":"Kafka","createdAt":"","updatedAt":"","count":0}],"metaTitle":"Clickstream analytics case study. Part I: Kafka -\u003e Data Transfer -\u003e ClickHouse","description":"\u003cp\u003eWritten By: Igor Mosyagin, Developer Advocate at\u0026nbsp;DoubleCloud\u003c/p\u003e","content":"\u003cp\u003eQuick navigation:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#intro\"\u003eIntro\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#data-solution-overview\"\u003eData Solution overview\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#problem-outline\"\u003eProblem outline\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sample-event\"\u003eSample event\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#setup-infrastructure\"\u003eSetup Infrastructure\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#setup-transfer-endpoints\"\u003eSetup transfer endpoints\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#creating-and-activating-the-transfer\"\u003eCreating and activating the Transfer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#producer-script\"\u003eProducer script\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sanity-checks-to-ensure-everything-works-as-expected\"\u003eSanity checks to\u0026nbsp;ensure everything works as\u0026nbsp;expected\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#adding-transformation\"\u003eAdding transformation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#check-the-final-result\"\u003eCheck the final result\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#wrap-up\"\u003eWrap up\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"intro\"\u003e\u003ca href=\"#intro\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eIntro\u003c/span\u003e\u003c/a\u003eIntro\u003c/h2\u003e\n\u003cp\u003eWelcome to\u0026nbsp;this series of\u0026nbsp;posts exploring a\u0026nbsp;real-time analytics use case. The series covers various aspects of\u0026nbsp;setting up\u0026nbsp;a\u0026nbsp;real-time analytics platform using DoubleCloud managed services, from data ingestion to\u0026nbsp;aggregation computation, and finally, to\u0026nbsp;dashboards based on\u0026nbsp;those data marts.\u003c/p\u003e\n\u003cp\u003eThis first post focuses on\u0026nbsp;the initial setup and data loading using ClickHouse, Apache Kafka, and DoubleCloud\u0026rsquo;s Data Transfer.\u003c/p\u003e\n\u003ch2 id=\"data-solution-overview\"\u003e\u003ca href=\"#data-solution-overview\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eData Solution overview\u003c/span\u003e\u003c/a\u003eData Solution overview\u003c/h2\u003e\n\u003cp\u003eBy\u0026nbsp;the end of\u0026nbsp;the series, we\u0026nbsp;will have built a\u0026nbsp;setup that enables us\u0026nbsp;to\u0026nbsp;ingest and make decisions based on\u0026nbsp;clickstream data. The overall architecture of\u0026nbsp;our data platform looks like this schematically:\u003c/p\u003e\n\n\u003cp\u003eIn\u0026nbsp;the diagram, the white part represents an\u0026nbsp;external data provider (such as\u0026nbsp;a\u0026nbsp;web performance monitoring tool), while everything else consists of\u0026nbsp;DoubleCloud managed services. We\u0026nbsp;will use a\u0026nbsp;simple Python script to\u0026nbsp;send data. This first part focuses on\u0026nbsp;data ingestion, the initial setup of\u0026nbsp;our Kafka server, and the data loading process for ClickHouse:\u003c/p\u003e\n\n\u003cp\u003eThe upcoming parts of\u0026nbsp;the series will focus on\u0026nbsp;aggregations and visualization. While we\u0026nbsp;will address performance when relevant, the primary goal of\u0026nbsp;the series is\u0026nbsp;to\u0026nbsp;describe connecting the various components together.\u003c/p\u003e\n\u003ch2 id=\"problem-outline\"\u003e\u003ca href=\"#problem-outline\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eProblem outline\u003c/span\u003e\u003c/a\u003eProblem outline\u003c/h2\u003e\n\u003cp\u003eOne of\u0026nbsp;the common tasks in\u0026nbsp;real-time analytics is\u0026nbsp;performing aggregations. We\u0026nbsp;have clickstream data and want to\u0026nbsp;visualize some basic metrics related to\u0026nbsp;user activity on\u0026nbsp;the website. In\u0026nbsp;this example, which will be\u0026nbsp;used throughout the entire series, we\u0026nbsp;will use a\u0026nbsp;subset of\u0026nbsp;fields from our clickstream data to\u0026nbsp;calculate how many products were purchased during specific hours of\u0026nbsp;the day.\u003c/p\u003e\n\u003ch2 id=\"sample-event\"\u003e\u003ca href=\"#sample-event\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eSample event\u003c/span\u003e\u003c/a\u003eSample event\u003c/h2\u003e\n\u003cp\u003eHere\u0026rsquo;s an\u0026nbsp;example event from our data source, representing user interactions with products in\u0026nbsp;a\u0026nbsp;marketplace. This event is\u0026nbsp;already enriched with additional information about the user and the item they interacted with:\u003c/p\u003e\n\n    \u003cdiv class=\"yfm-clipboard\"\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs json\"\u003e\u003cspan class=\"hljs-punctuation\"\u003e{\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"basket_price\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"detectedCorruption\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003e\u003cspan class=\"hljs-keyword\"\u003efalse\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"detectedDuplicate\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003e\u003cspan class=\"hljs-keyword\"\u003efalse\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"eventType\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"itemViewEvent\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"firstInSession\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003e\u003cspan class=\"hljs-keyword\"\u003etrue\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"item_id\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"bx_VHZvTOyk_CYNTZGlxyopNGYodgtybLKqToopjOqbT\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"item_price\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e4876\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"item_url\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"https://mu3bxs.webshop24.eu/katalog/item/t-shirt-female-temptation/\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"location\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"https://mu3bxs.webshop24.eu/\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"pageViewId\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"0:qawVTkAI:IyqIWWkimHqgvBGCbeMMIoosmXiuLcvW\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"partyId\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"0:ckQoIhoa:PtdjtCnxGtRzfXvovHcDtltPSaDzpvxM\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"referer\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"https://mu3bxs.webshop24.eu//katalog/item/slippers-pink-paradise/\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"remoteHost\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"test0\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"sessionId\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"0:ZSMAmydy:yqxDDTWQfbRtrauPYAAIGQsCVubHrdov\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"timestamp\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e1545127200000\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"userAgentName\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36\"\u003c/span\u003e\n\u003cspan class=\"hljs-punctuation\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\n    \u003csvg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" class=\"yfm-clipboard-button\" data-animation=\"15\"\u003e\n        \u003cpath fill=\"currentColor\" d=\"M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z\"\u003e\u003c/path\u003e\n        \u003cpath stroke=\"currentColor\" fill=\"transparent\" stroke-width=\"1.5\" d=\"M9.5 13l3 3l5 -5\" visibility=\"hidden\"\u003e\n            \u003canimate id=\"visibileAnimation-15\" attributeName=\"visibility\" from=\"hidden\" to=\"visible\" dur=\"0.2s\" fill=\"freeze\" begin\u003e\u003c/animate\u003e\n            \u003canimate id=\"hideAnimation-15\" attributeName=\"visibility\" from=\"visible\" to=\"hidden\" dur=\"1s\" begin=\"visibileAnimation-15.end+1\" fill=\"freeze\"\u003e\u003c/animate\u003e\n        \u003c/path\u003e\n    \u003c/svg\u003e\n    \u003c/div\u003e\n\u003cp\u003eFor the purpose of\u0026nbsp;our example pipeline, we\u0026nbsp;will concentrate on\u0026nbsp;a\u0026nbsp;subset of\u0026nbsp;the event\u0026rsquo;s fields and set our ingestion pipeline to\u0026nbsp;use only the ones we\u0026rsquo;re interested\u0026nbsp;in. To\u0026nbsp;compute aggregated statistics, we\u0026nbsp;will need the following fields:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003epartyId\u003c/code\u003e (string key, denoting global userId)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003esessionId\u003c/code\u003e (string key, used to\u0026nbsp;mark the same user session)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eitem_price\u003c/code\u003e (integer representing the price of\u0026nbsp;an\u0026nbsp;item)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eeventType\u003c/code\u003e (string field for the type of\u0026nbsp;event)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003edetectedDuplicate\u003c/code\u003e and \u003ccode\u003edetectedCorruption\u003c/code\u003e (boolean fields from upcoming data enrichment systems that will be\u0026nbsp;used to\u0026nbsp;filter data)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEverything else is\u0026nbsp;unnecessary for our example use case, but it\u0026rsquo;s helpful to\u0026nbsp;know what those fields are in\u0026nbsp;case there is\u0026nbsp;a\u0026nbsp;need for further analysis later.\u003c/p\u003e\n\u003cp\u003eThe Python code, along with sample data and instructions on\u0026nbsp;how to\u0026nbsp;run it, can be\u0026nbsp;found \u003ca href=\"https://github.com/doublecloud/showcase-webshop-clickstream-aggregation\"\u003ein\u0026nbsp;this repository\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"setup-infrastructure\"\u003e\u003ca href=\"#setup-infrastructure\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eSetup infrastructure\u003c/span\u003e\u003c/a\u003eSetup infrastructure\u003c/h2\u003e\n\u003ch3 id=\"kafka-cluster\"\u003e\u003ca href=\"#kafka-cluster\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eKafka cluster\u003c/span\u003e\u003c/a\u003eKafka cluster\u003c/h3\u003e\n\u003cp\u003eWe\u0026nbsp;will use Kafka as\u0026nbsp;our ingestion layer. For the purposes of\u0026nbsp;this series, we\u0026nbsp;can go\u0026nbsp;with the default options: select the eu-central-1 zone and choose the smallest possible configuration. The only change I\u0026nbsp;would personally recommend is\u0026nbsp;opting for an\u0026nbsp;ARM architecture, as\u0026nbsp;it\u0026nbsp;tends to\u0026nbsp;perform slightly better, as\u0026nbsp;highlighted in\u0026nbsp;our article on\u0026nbsp;this topic: \u003ca href=\"https://double.cloud/blog/posts/2024/06/benchmarking-apache-kafka-performance-per-price/\"\u003eBenchmarking Apache Kafka: performance per price\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSimply pick a\u0026nbsp;cluster name you\u0026rsquo;re comfortable with, select a\u0026nbsp;recent Kafka version (3.5), and you\u0026rsquo;re all set!\u003c/p\u003e\n\n\u003cp\u003eProvisioning should take a\u0026nbsp;few minutes (we\u0026nbsp;can create the ClickHouse cluster in\u0026nbsp;the meantime). Once the cluster is\u0026nbsp;up\u0026nbsp;and running, let\u0026rsquo;s navigate to\u0026nbsp;cluster settings and create a\u0026nbsp;topic for our events.\u003c/p\u003e\n\u003ch4 id=\"kafka-topic-for-incoming-messages\"\u003e\u003ca href=\"#kafka-topic-for-incoming-messages\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eKafka topic for incoming messages\u003c/span\u003e\u003c/a\u003eKafka topic for incoming messages\u003c/h4\u003e\n\u003cp\u003eWe\u0026nbsp;will be\u0026nbsp;using a\u0026nbsp;standard architectural pattern of\u0026nbsp;having a\u0026nbsp;single topic per schema, meaning that each different schema of\u0026nbsp;messages will be\u0026nbsp;assigned to\u0026nbsp;a\u0026nbsp;separate topic. Therefore, we\u0026nbsp;need to\u0026nbsp;create a\u0026nbsp;topic for incoming messages, which can be\u0026nbsp;done through the same cluster control interface.\u003c/p\u003e\n\n\u003cp\u003eFor the purpose of\u0026nbsp;this tutorial, our load is\u0026nbsp;non-threatening, so\u0026nbsp;we\u0026nbsp;can use a\u0026nbsp;simple topic with just one partition and a\u0026nbsp;replication factor of\u0026nbsp;one.\u003c/p\u003e\n\u003ch4 id=\"allowlist-caveat\"\u003e\u003ca href=\"#allowlist-caveat\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eAllowList caveat\u003c/span\u003e\u003c/a\u003eAllowList caveat\u003c/h4\u003e\n\u003cp\u003eTo\u0026nbsp;simplify testing, DoubleCloud adds your IP\u0026nbsp;address to\u0026nbsp;the \u003cstrong\u003eALLOW LIST\u003c/strong\u003e in\u0026nbsp;the cluster settings. Keep this in\u0026nbsp;mind if\u0026nbsp;you frequently switch Wi-Fi networks while working from your laptop.\u003c/p\u003e\n\u003ch3 id=\"clickhouse-cluster\"\u003e\u003ca href=\"#clickhouse-cluster\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eClickHouse cluster\u003c/span\u003e\u003c/a\u003eClickHouse cluster\u003c/h3\u003e\n\u003cp\u003eFor the ClickHouse cluster, let\u0026rsquo;s select the same availability zone and opt for the smallest possible setup: 1\u0026nbsp;replica and 1\u0026nbsp;shard, resulting in\u0026nbsp;a\u0026nbsp;single ARM node with just 32\u0026nbsp;GB\u0026nbsp;of\u0026nbsp;storage. While you would typically want a\u0026nbsp;more robust configuration for production, these defaults are sufficient for our current needs. We\u0026rsquo;ll discuss scaling a\u0026nbsp;bit in\u0026nbsp;future parts of\u0026nbsp;this series.\u003c/p\u003e\n\n\u003cp\u003eChoose a\u0026nbsp;reasonable name for the cluster and select a\u0026nbsp;relevant version. The cluster creation UI\u0026nbsp;defaults to\u0026nbsp;the latest LTS version, but there\u0026rsquo;s nothing stopping us\u0026nbsp;from opting for a\u0026nbsp;more recent one.\u003c/p\u003e\n\u003ch4 id=\"clickhouse-database\"\u003e\u003ca href=\"#clickhouse-database\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eClickHouse database\u003c/span\u003e\u003c/a\u003eClickHouse database\u003c/h4\u003e\n\u003cp\u003eWhile we\u0026nbsp;can use the default database for ClickHouse, it\u0026nbsp;makes sense to\u0026nbsp;create a\u0026nbsp;different one for our application. Let\u0026rsquo;s go\u0026nbsp;ahead and do\u0026nbsp;that. There are multiple ways to\u0026nbsp;access our cluster, but the easiest method is\u0026nbsp;to\u0026nbsp;use the WebSQL interface. From the cluster interface, click on\u0026nbsp;the \u003cstrong\u003eWebSQL\u003c/strong\u003e button to\u0026nbsp;open the interface in\u0026nbsp;the new tab.\u003c/p\u003e\n\n\u003cp\u003eThis will automatically connect to\u0026nbsp;the cluster and authorize with admin credentials. Clicking on\u0026nbsp;any entity in\u0026nbsp;the left tree menu will open the query editor. Execute the following code to\u0026nbsp;create a\u0026nbsp;new database:\u003c/p\u003e\n\n    \u003cdiv class=\"yfm-clipboard\"\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs sql\"\u003e\u003cspan class=\"hljs-keyword\"\u003eCREATE\u003c/span\u003e DATABASE webshop;\n\u003c/code\u003e\u003c/pre\u003e\n\n    \u003csvg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" class=\"yfm-clipboard-button\" data-animation=\"3\"\u003e\n        \u003cpath fill=\"currentColor\" d=\"M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z\"\u003e\u003c/path\u003e\n        \u003cpath stroke=\"currentColor\" fill=\"transparent\" stroke-width=\"1.5\" d=\"M9.5 13l3 3l5 -5\" visibility=\"hidden\"\u003e\n            \u003canimate id=\"visibileAnimation-3\" attributeName=\"visibility\" from=\"hidden\" to=\"visible\" dur=\"0.2s\" fill=\"freeze\" begin\u003e\u003c/animate\u003e\n            \u003canimate id=\"hideAnimation-3\" attributeName=\"visibility\" from=\"visible\" to=\"hidden\" dur=\"1s\" begin=\"visibileAnimation-3.end+1\" fill=\"freeze\"\u003e\u003c/animate\u003e\n        \u003c/path\u003e\n    \u003c/svg\u003e\n    \u003c/div\u003e\n\n\u003cp\u003eI\u0026nbsp;suggest naming the new database \u003cstrong\u003ewebshop\u003c/strong\u003e, and I\u0026nbsp;will use this name in\u0026nbsp;the examples moving forward. Now that we\u0026nbsp;have our source and destination set up, let\u0026rsquo;s create a\u0026nbsp;\u003cstrong\u003eData Transfer\u003c/strong\u003e pipeline to\u0026nbsp;connect them.\u003c/p\u003e\n\u003ch4 id=\"allowlist-caveat\"\u003e\u003ca href=\"#allowlist-caveat\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eAllowList caveat\u003c/span\u003e\u003c/a\u003eAllowList caveat\u003c/h4\u003e\n\u003cp\u003eSimilar to\u0026nbsp;the Kafka cluster, DoubleCloud adds your IP\u0026nbsp;address to\u0026nbsp;the \u003cstrong\u003eALLOW LIST\u003c/strong\u003e in\u0026nbsp;the cluster settings behind the scenes. Keep this in\u0026nbsp;mind if\u0026nbsp;you frequently switch Wi-Fi networks while working from your laptop. It\u0026nbsp;is\u0026nbsp;advised not to\u0026nbsp;open your cluster to\u0026nbsp;the world carelessly, even for short-term testing purposes.\u003c/p\u003e\n\u003ch2 id=\"setup-transfer-endpoints\"\u003e\u003ca href=\"#setup-transfer-endpoints\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eSetup transfer endpoints\u003c/span\u003e\u003c/a\u003eSetup transfer endpoints\u003c/h2\u003e\n\u003cp\u003eDoubleCloud provides a\u0026nbsp;convenient way to\u0026nbsp;ingest data from Kafka to\u0026nbsp;ClickHouse through a\u0026nbsp;tool called \u003ca href=\"https://double.cloud/services/doublecloud-transfer/\"\u003eData Transfer\u003c/a\u003e. We\u0026nbsp;will use \u003cstrong\u003eTransfer\u003c/strong\u003e to\u0026nbsp;read data from our \u003cstrong\u003eKafka topic\u003c/strong\u003e (referred to\u0026nbsp;as\u0026nbsp;the source endpoint in\u0026nbsp;Transfer\u0026rsquo;s terminology) and publish it\u0026nbsp;to\u0026nbsp;\u003cstrong\u003eClickHouse\u003c/strong\u003e (the target endpoint in\u0026nbsp;Transfer\u0026rsquo;s terminology). Let\u0026rsquo;s set it\u0026nbsp;up!\u003c/p\u003e\n\u003ch3 id=\"kafka-transport-source-endpoint\"\u003e\u003ca href=\"#kafka-transport-source-endpoint\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eKafka: Transport source endpoint\u003c/span\u003e\u003c/a\u003eKafka: Transport source endpoint\u003c/h3\u003e\n\u003cp\u003eNavigate to\u0026nbsp;the \u003cstrong\u003eTransfer\u003c/strong\u003e page, switch to\u0026nbsp;the \u003cstrong\u003eEndpoint\u003c/strong\u003e tab, and create a\u0026nbsp;source endpoint. Select \u003cstrong\u003eKafka\u003c/strong\u003e as\u0026nbsp;the source type in\u0026nbsp;the dropdown and give it\u0026nbsp;a\u0026nbsp;reasonable name (this name will be\u0026nbsp;used internally by\u0026nbsp;Transfer).\u003c/p\u003e\n\n\u003cp\u003eSelect the recently created Kafka cluster and use the credentials to\u0026nbsp;connect to\u0026nbsp;it\u0026nbsp;via SASL. To\u0026nbsp;make the endpoint functional, add the topic that was created earlier.\u003c/p\u003e\n\u003ch4 id=\"json-fields\"\u003e\u003ca href=\"#json-fields\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eJSON fields\u003c/span\u003e\u003c/a\u003eJSON fields\u003c/h4\u003e\n\u003cp\u003eSince the initial analysis of\u0026nbsp;event data showed that we\u0026nbsp;don\u0026rsquo;t need all the fields, we\u0026nbsp;can include only the ones we\u0026nbsp;are interested\u0026nbsp;in. This can be\u0026nbsp;done using the \u003cstrong\u003eAdvanced settings\u003c/strong\u003e tab, where we\u0026nbsp;can specify a\u0026nbsp;JSON conversion rule with a\u0026nbsp;list of\u0026nbsp;relevant fields. Here\u0026rsquo;s what I\u0026nbsp;ended up\u0026nbsp;with:\u003c/p\u003e\n\n\u003cp\u003eAdditionally, since I\u0026nbsp;might be\u0026nbsp;interested in\u0026nbsp;other fields later, I\u0026rsquo;ll make sure that a\u0026nbsp;corresponding option is\u0026nbsp;enabled, just in\u0026nbsp;case.\u003c/p\u003e\n\u003ch3 id=\"clickhouse-transport-target-endpoint\"\u003e\u003ca href=\"#clickhouse-transport-target-endpoint\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eClickHouse: Transport target endpoint\u003c/span\u003e\u003c/a\u003eClickHouse: Transport target endpoint\u003c/h3\u003e\n\u003cp\u003eCreating the target endpoint is\u0026nbsp;straightforward as\u0026nbsp;well. There\u0026rsquo;s no\u0026nbsp;need for any additional setup; simply select the connection type, choose the correct cluster from the dropdown menu, and specify the target database (schema).\u003c/p\u003e\n\n\u003cp\u003eNow that both endpoints are set up, we\u0026nbsp;need to\u0026nbsp;create the transfer itself.\u003c/p\u003e\n\u003ch2 id=\"creating-and-activating-the-transfer\"\u003e\u003ca href=\"#creating-and-activating-the-transfer\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eCreating and activating the Transfer\u003c/span\u003e\u003c/a\u003eCreating and activating the Transfer\u003c/h2\u003e\n\u003cp\u003eWe\u0026nbsp;need to\u0026nbsp;specify the created endpoints, choose a\u0026nbsp;name, and that\u0026rsquo;s\u0026nbsp;it. Everything else can be\u0026nbsp;left at\u0026nbsp;the default settings. Click \u003cstrong\u003e\u0026ldquo;Submit\u0026rdquo;\u003c/strong\u003e and grab a\u0026nbsp;cup of\u0026nbsp;tea while the transfer is\u0026nbsp;being created.\u003c/p\u003e\n\n\u003cp\u003eOnce the transfer is\u0026nbsp;created, we\u0026nbsp;need to\u0026nbsp;activate it\u0026nbsp;and ensure it\u0026nbsp;is\u0026nbsp;running (its status should change accordingly).\u003c/p\u003e\n\n\u003ch2 id=\"producer-script\"\u003e\u003ca href=\"#producer-script\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eProducer script\u003c/span\u003e\u003c/a\u003eProducer script\u003c/h2\u003e\n\u003cp\u003eTo\u0026nbsp;test the pipeline, we\u0026nbsp;will be\u0026nbsp;producing 1,000 events from a\u0026nbsp;file using a\u0026nbsp;Python script. \u003ca href=\"https://github.com/doublecloud/showcase-webshop-clickstream-aggregation\"\u003eYou can check the source here\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eTo\u0026nbsp;run the script, install the required packages, set the environment variables for cluster access, and execute the following command in\u0026nbsp;the terminal:\u003c/p\u003e\n\n    \u003cdiv class=\"yfm-clipboard\"\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs python\"\u003eclickstream/produce_events.py\n\u003c/code\u003e\u003c/pre\u003e\n\n    \u003csvg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" class=\"yfm-clipboard-button\" data-animation=\"9\"\u003e\n        \u003cpath fill=\"currentColor\" d=\"M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z\"\u003e\u003c/path\u003e\n        \u003cpath stroke=\"currentColor\" fill=\"transparent\" stroke-width=\"1.5\" d=\"M9.5 13l3 3l5 -5\" visibility=\"hidden\"\u003e\n            \u003canimate id=\"visibileAnimation-9\" attributeName=\"visibility\" from=\"hidden\" to=\"visible\" dur=\"0.2s\" fill=\"freeze\" begin\u003e\u003c/animate\u003e\n            \u003canimate id=\"hideAnimation-9\" attributeName=\"visibility\" from=\"visible\" to=\"hidden\" dur=\"1s\" begin=\"visibileAnimation-9.end+1\" fill=\"freeze\"\u003e\u003c/animate\u003e\n        \u003c/path\u003e\n    \u003c/svg\u003e\n    \u003c/div\u003e\n\u003cp\u003eThis will produce 1,000 events from the file \u003cstrong\u003eevents1000.jsonl\u003c/strong\u003e. Refer to\u0026nbsp;the \u003ccode\u003eREADME\u003c/code\u003e if\u0026nbsp;you want to\u0026nbsp;customize something, encounter any issues or\u0026nbsp;if\u0026nbsp;you want to\u0026nbsp;manipulate the data first, such as\u0026nbsp;moving it\u0026nbsp;in\u0026nbsp;time if\u0026nbsp;needed.\u003c/p\u003e\n\u003ch2 id=\"sanity-checks-to-ensure-everything-works-as-expected\"\u003e\u003ca href=\"#sanity-checks-to-ensure-everything-works-as-expected\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eSanity checks to\u0026nbsp;ensure everything works as\u0026nbsp;expected\u003c/span\u003e\u003c/a\u003eSanity checks to\u0026nbsp;ensure everything works as\u0026nbsp;expected\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s perform some queries from the WebSQL interface to\u0026nbsp;check our data. If\u0026nbsp;we\u0026nbsp;open WebSQL Query editor, we\u0026nbsp;can see that all 1,000 events have arrived:\u003c/p\u003e\n\n\u003cp\u003eThe next logical step is\u0026nbsp;to\u0026nbsp;verify that the timestamps are in\u0026nbsp;the expected format:\u003c/p\u003e\n\n\u003cp\u003eIt\u0026nbsp;appears that the dates are slightly too futuristic. A\u0026nbsp;common issue with numeric timestamps from different systems is\u0026nbsp;that they might use different time formats. For example, one system might use microseconds while another uses seconds. Let\u0026rsquo;s see if\u0026nbsp;dividing the timestamp resolves the issue:\u003c/p\u003e\n\n\u003cp\u003eAnd indeed, it\u0026nbsp;does! We\u0026nbsp;now have two options:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAccount for the fact that our timestamps need special treatment before proceeding with the analysis.\u003c/li\u003e\n\u003cli\u003eTransform the timestamps upon ingestion.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTypical data modeling approach is\u0026nbsp;to\u0026nbsp;choose the first option, where you don\u0026rsquo;t modify data at\u0026nbsp;the ingestion \u003cstrong\u003e\u0026ldquo;source\u0026rdquo;\u003c/strong\u003e level and instead perform preparation in\u0026nbsp;the next stage.\u003c/p\u003e\n\u003cp\u003eHowever, in\u0026nbsp;modern data pipelines, it\u0026nbsp;is\u0026nbsp;generally acceptable to\u0026nbsp;perform simple transformations during ingestion, as\u0026nbsp;long as\u0026nbsp;they are indeed straightforward. Thankfully, Transfer is\u0026nbsp;capable of\u0026nbsp;doing just that!\u003c/p\u003e\n\u003ch2 id=\"adding-transformation\"\u003e\u003ca href=\"#adding-transformation\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eAdding transformation\u003c/span\u003e\u003c/a\u003eAdding transformation\u003c/h2\u003e\n\u003cp\u003eIf\u0026nbsp;we\u0026nbsp;go\u0026nbsp;back to\u0026nbsp;our transfer and open \u003cstrong\u003eEdit\u003c/strong\u003e view, we\u0026rsquo;ll find a\u0026nbsp;button labeled \u003cstrong\u003e\u0026ldquo;Transformation\u0026rdquo;\u003c/strong\u003e towards the end of\u0026nbsp;the page:\u003c/p\u003e\n\n\u003cp\u003eThis humble little feature is\u0026nbsp;exactly what we\u0026nbsp;need for our transformation. Transfer supports multiple ways to\u0026nbsp;adjust your data as\u0026nbsp;it\u0026nbsp;moves between endpoints. We\u0026nbsp;will use the on-the-fly SQL processor. Click on\u0026nbsp;the button and select \u003cstrong\u003e\u0026ldquo;SQL\u0026rdquo;\u003c/strong\u003e from the Transformer dropdown. I\u0026rsquo;ll create a\u0026nbsp;new field called \u003cstrong\u003e\u0026ldquo;my_ts\u0026rdquo;\u003c/strong\u003e that will hold the original timestamp divided by\u0026nbsp;1,000:\u003c/p\u003e\n\n\u003cp\u003eBy\u0026nbsp;the way, Transfer allows you to\u0026nbsp;stack multiple transformations in\u0026nbsp;a\u0026nbsp;chain of\u0026nbsp;operations if\u0026nbsp;you wish. However, there are some limitations to\u0026nbsp;what is\u0026nbsp;possible and, more importantly, what should be\u0026nbsp;done at\u0026nbsp;this step. Keep in\u0026nbsp;mind that these operations are effectively hidden from your view, so\u0026nbsp;you should avoid extensive data transformations here and instead leave that to\u0026nbsp;your ETL processes in\u0026nbsp;the next stage of\u0026nbsp;the data processing pipeline.\u003c/p\u003e\n\u003ch2 id=\"check-the-final-result\"\u003e\u003ca href=\"#check-the-final-result\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eCheck the final result\u003c/span\u003e\u003c/a\u003eCheck the final result\u003c/h2\u003e\n\u003cp\u003eUpdate the transfer, drop the table (since we\u0026nbsp;are altering the scheme, this is\u0026nbsp;the easiest way to\u0026nbsp;update it), produce new data, and voil\u0026agrave;! We\u0026nbsp;have our timestamp in\u0026nbsp;expected format and within the correct century.\u003c/p\u003e\n\n\u003ch2 id=\"wrap-up\"\u003e\u003ca href=\"#wrap-up\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eWrap up\u003c/span\u003e\u003c/a\u003eWrap up\u003c/h2\u003e\n\u003cp\u003eIn\u0026nbsp;just a\u0026nbsp;few clicks, we\u0026nbsp;have created a\u0026nbsp;Kafka cluster, a\u0026nbsp;ClickHouse cluster, and a\u0026nbsp;Transfer pipeline with on-the-fly data transformation that now ingests incoming data in\u0026nbsp;our database. We\u0026nbsp;have everything ready to\u0026nbsp;start computing aggregates, which we\u0026nbsp;will cover in\u0026nbsp;the next part. Stay tuned for Part II!\u003c/p\u003e\n\u003cp\u003eIf\u0026nbsp;you have any questions or\u0026nbsp;would like to\u0026nbsp;discuss this series further, feel free to\u0026nbsp;\u003ca href=\"https://join.slack.com/t/double-cloud/shared_invite/zt-1pbz9lfte-5GoIX~8CmVYqmVQfRFPNdA\"\u003ereach out on\u0026nbsp;Slack\u003c/a\u003e.\u003c/p\u003e\n"},"suggestedPosts":[{"url":"/blog/posts/2023/07/unifying-real-time-data-processing-kafka-spark-and-clickhouse","id":124,"name":"unifying-real-time-data-processing-kafka-spark-and-clickhouse","date":"2023-07-17T00:00:00Z","description":"Written by: Amos Gutman, DoubleCloud Senior Solution Architect","readingTime":10,"image":"/assets/blog/articles/unifying-real-time-data-processing-kafka-spark-and-clickhouse-cover.png","blogPostId":124,"likes":0,"hasUserLike":false,"slug":"","title":"Unifying real-time data processing: Kafka, Spark, and ClickHouse","authors":[],"tags":[],"locale":{"lang":"en"},"textTitle":"Unifying real-time data processing: Kafka, Spark, and ClickHouse","htmlTitle":"Unifying real-time data processing: Kafka, Spark, and ClickHouse"},{"url":"/blog/posts/2024/02/kafka-and-clickhouse-unlocking-the-power-duo","id":148,"name":"kafka-and-clickhouse-unlocking-the-power-duo","date":"2024-02-21T00:00:00Z","description":"Written by: Andrei Tserakhau, DoubleCloud Tech Lead","readingTime":15,"image":"/assets/blog/articles/kafka-clickhouse-schema-cover.png","blogPostId":148,"likes":0,"hasUserLike":false,"slug":"","title":"Unlocking the power duo: Kafka and ClickHouse for lightning-fast data processing","authors":[],"tags":[],"locale":{"lang":"en"},"textTitle":"Unlocking the power duo: Kafka and ClickHouse for lightning-fast data processing","htmlTitle":"Unlocking the power duo: Kafka and ClickHouse for lightning-fast data processing"},{"url":"/blog/posts/2024/07/7-essential-tips-for-a-production-clickhouse-cluster","id":160,"name":"7-essential-tips-for-a-production-clickhouse-cluster","date":"2024-07-29T00:00:00Z","description":"Written by: Vladimir Ivoninskii","readingTime":10,"image":"/assets/blog/articles/2024/7-essential-tips-for-a-production-clickhouse-cluster-small-cover.png","blogPostId":160,"likes":0,"hasUserLike":false,"slug":"","title":"7 essential tips for a production ClickHouse cluster","authors":[],"tags":[],"locale":{"lang":"en"},"textTitle":"7 essential tips for a production ClickHouse cluster","htmlTitle":"7 essential tips for a production ClickHouse cluster"}]}},"navigationData":{"newMenu":true,"header":{"leftItems":[{"text":"Why DoubleCloud","type":"dc-dropdown","data":{"view":"list","groups":[{"items":[{"text":"Performance","url":"/performance-boost/","description":"Get the best performance with the highest ROI"},{"text":"Security","url":"/security/","description":"Keep your data protected and maintain compliance"},{"text":"DoubleCloud vs. other solutions","url":"/comparison/","description":"Learn how DoubleCloud’s products compare to other solutions"},{"text":"Customer stories","url":"/resources/case-studies/","description":"See our solutions in action"}]},{"image":{"src":"/assets/doublecloud/menu-bar/menu-banner-dc-results.png.webp","style":{"width":300,"height":300}},"text":"\u003ca href='/performance-boost/' target='_self'\u003eGet more and spend less with DoubleCloud  →\u003c/a\u003e"}]}},{"text":"Products","type":"dc-dropdown","metaSchema":{"@graph":[{"@type":"SoftwareApplication","sameAs":["https://twitter.com/getdoublecloud","https://www.youtube.com/@doublecloud2499","https://www.linkedin.com/company/doublecloudplatform/","https://www.facebook.com/GetDoubleCloud/"]},{"@context":"https://schema.org","@type":"Organization","foundingDate":2022,"contactPoint":{"@type":"ContactPoint","contactType":"customer support","telephone":"+1 302-658-7581","email":"info@double.cloud"},"sameAs":["https://twitter.com/getdoublecloud","https://www.youtube.com/@doublecloud2499","https://www.linkedin.com/company/doublecloudplatform/","https://www.facebook.com/GetDoubleCloud/"]}]},"data":{"items":[{"text":"Managed Service for ClickHouse®","url":"/services/managed-clickhouse/","icon":"/assets/icons/dc-clickhouse.svg","description":"The fastest, most resource-efficient OLAP database for real-time analytics"},{"text":"Managed Service for Apache Kafka®","url":"/services/managed-kafka/","icon":"/assets/icons/dc-kafka.svg","description":"A leading data streaming technology for large-scale, data-intensive applications"},{"text":"Managed Service for Apache Airflow®","url":"/services/managed-airflow/","icon":"/assets/icons/dc-airflow.svg","description":"Open-source tool to orchestrate and monitor workflows"},{"text":"Data Transfer","url":"/services/doublecloud-transfer/","icon":"/assets/icons/dc-transfer.svg","description":"No-code ELT tool for aggregating, collecting, and migrating data"},{"text":"Data Visualization","url":"/services/doublecloud-visualization/","icon":"/assets/icons/dc-data-vis.svg","description":"Free tool to create, modify, and share dashboards and charts"}]}},{"text":"Solutions","type":"dc-dropdown","data":{"view":"list","groups":[{"title":"By use case","items":[{"text":"Customer-facing analytics","url":"/solutions/customer-facing-analytics/","description":"Provide business insights for your clients or partners"},{"text":"Real-time analytics","url":"/solutions/real-time-analytics/","description":"Build a data infrastructure to collect, process, and analyze data in real time"},{"text":"Observability and monitoring","url":"/solutions/observability-and-monitoring/","description":"Analyze terabytes of your logs, events, and traces with ease"}]},{"title":"By industry","items":[{"text":"AdTech and MarTech data analytics","url":"/solutions/adtech/","description":"Extract and analyze data from Meta ads, Google ads, LinkedIn ads, and others"},{"text":"Analytics for mobile and gaming apps","url":"/solutions/web-mobile-gaming-apps/","description":"Optimize and scale your mobile and gaming app analytics"},{"text":"EdTech data analytics","url":"/solutions/edtech/","description":"Improve online learning and identify new sales opportunities"},{"text":"FinTech data analytics","url":"/solutions/fintech-real-time-analytics/","description":"Manage and process large amounts of financial data efficiently"}]}]}},{"text":"Resources","type":"dc-dropdown","data":{"view":"list","groups":[{"title":"Using DoubleCloud","items":[{"text":"DoubleCloud API","url":"/docs/en/public-api/","description":"Read up on API tutorials and instructions","target":"_self"},{"text":"Terraform","url":"/docs/en/developer-resources/terraform/create-resources","description":"Deploy and manage cloud resources with the infrastructure-as-code approach"},{"text":"Status updates","url":"https://status.double.cloud/","description":"Check the current operational status of our services"},{"text":"Support","url":"/support/","description":"Learn more about our support tiers"}]},{"title":"Discover","items":[{"text":"Webinars","url":"/webinars/","description":"Sign up for the next webinar or watch previous ones"},{"text":"Blog","url":"/blog/","description":"Get insights from our team and the latest news"}]},{"image":{"src":"/assets/doublecloud/menu-bar/menu-banners-dc-ebook.png.webp","style":{"width":300,"height":300}},"text":"\u003ca href='/resources/clickhouse-ebook/' target='_self'\u003eGrab your ebook  →\u003c/a\u003e"}]}},{"text":"Company","type":"dc-dropdown","data":{"items":[{"text":"About DoubleCloud","url":"/company/about-us/"},{"text":"Careers","url":"/company/careers/"},{"text":"Contact us","url":"/company/contact-us/"}]}},{"text":"Pricing","url":"/pricing/"},{"text":"Documentation","url":"/docs/en/","target":"_self"}],"rightItems":[{"type":"button","text":"Slack","url":"https://join.slack.com/t/double-cloud/shared_invite/zt-1pbz9lfte-5GoIX~8CmVYqmVQfRFPNdA","img":"/assets/icons/slack.svg","theme":"flat"},{"type":"button","text":"Contact us","theme":"flat","url":"#contact-us-form"},{"type":"button","text":"Console","url":"https://app.double.cloud","theme":"accent"}]},"logo":{"icon":"/assets/logo/dc-logo-dark.svg","text":""},"footer":{"subscriptionForm":{"header":"Subscribe to our newsletter","footer":"By submitting this form, you agree to our \u003ca href=\"/legal/en/privacy/\"\u003ePrivacy policy\u003c/a\u003e","form":{"scriptSrc":"//js-eu1.hsforms.net/forms/embed/v2.js","region":"eu1","portalId":"25659674","formId":"b9015518-c7ea-4173-a96b-a251994635e3"}},"underline":{"links":[{"text":"Customer Agreement","url":"/legal/en/customer_agreement/","target":"_blank"},{"text":"Privacy Policy","url":"/legal/en/privacy/","target":"_blank"},{"text":"Pricing","url":"/pricing/"},{"text":"Security","url":"/security/","target":"_blank"}],"copyright":"© 2024 DoubleCloud"},"columns":[{"title":"Products","links":[{"text":"Managed Service for ClickHouse®","url":"/services/managed-clickhouse/"},{"text":"Managed Service for Apache Kafka®","url":"/services/managed-kafka/"},{"text":"Managed Service for Apache Airflow®","url":"/services/managed-airflow"},{"text":"Data Transfer","url":"/services/doublecloud-transfer/"},{"text":"Data Visualization","url":"/services/doublecloud-visualization"}]},{"title":"Solutions","links":[{"text":"Case studies","url":"/resources/case-studies/"},{"text":"Customer-facing analytics","url":"/solutions/customer-facing-analytics/"},{"text":"Real-time analytics","url":"/solutions/real-time-analytics/"},{"text":"Observability and monitoring","url":"/solutions/observability-and-monitoring/"},{"text":"AdTech and MarTech data analytics","url":"/solutions/adtech/"},{"text":"Analytics for mobile and gaming Apps","url":"/solutions/web-mobile-gaming-apps/"},{"text":"EdTech data analytics","url":"/solutions/edtech/"},{"text":"FinTech data analytics","url":"/solutions/fintech-real-time-analytics/"}]},{"title":"Resources","links":[{"text":"Documentation","url":"/docs/en/"},{"text":"Webinars","url":"/webinars/"},{"text":"Blog","url":"/blog/"},{"text":"Slack","url":"https://join.slack.com/t/double-cloud/shared_invite/zt-1pbz9lfte-5GoIX~8CmVYqmVQfRFPNdA"},{"text":"Support","url":"/support/"},{"text":"Status updates","url":"https://status.double.cloud/"},{"text":"Product comparisons","url":"/comparison/"},{"text":"Site map","url":"/sitemap/"}]},{"title":"Company","links":[{"text":"About DoubleCloud","url":"/company/about-us/"},{"text":"Careers","url":"/company/careers"},{"text":"AWS Partnership","url":"/aws-partnership/"},{"text":"Contact us","url":"/company/contact-us/"}]}]},"forms":{"contact":"11819433.daba96b39df83b7903708cc4842e9dbb9c944cce"},"favicon":{"folder":"/assets/favicon"},"analytics":{"id":"GTM-5M39N8J","ignore":true,"popup":{"text":"\u003cp\u003eBy\u0026nbsp;clicking \u0026ldquo;Accept\u0026rdquo;, you agree to\u0026nbsp;the storing of\u0026nbsp;cookies on\u0026nbsp;your device to\u0026nbsp;help us\u0026nbsp;analyze site usage and assist in\u0026nbsp;our marketing efforts. However, you may \u0026ldquo;Decline\u0026rdquo; that. More details here in\u0026nbsp;\u003ca href=\"/legal/en/privacy/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e","buttons":{"accept":{"size":"xl","text":"Accept"},"decline":{"size":"xl","text":"Decline"}}}}},"meta":{"title":"Clickstream analytics case study. Part I: Kafka -\u003e Data Transfer -\u003e ClickHouse | DoubleCloud","date":"2024-09-06T00:00:00Z","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-sharing.png","canonicalUrl":"","organization":{"appTitle":"DoubleCloud","legalName":"DoubleCloud Inc","supportEmail":"","url":"https://double.cloud"},"description":"How to set up a real-time analytics pipeline using Kafka and ClickHouse: initial setup and data loading.","content":"\u003cp\u003eQuick navigation:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#intro\"\u003eIntro\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#data-solution-overview\"\u003eData Solution overview\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#problem-outline\"\u003eProblem outline\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sample-event\"\u003eSample event\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#setup-infrastructure\"\u003eSetup Infrastructure\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#setup-transfer-endpoints\"\u003eSetup transfer endpoints\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#creating-and-activating-the-transfer\"\u003eCreating and activating the Transfer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#producer-script\"\u003eProducer script\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sanity-checks-to-ensure-everything-works-as-expected\"\u003eSanity checks to\u0026nbsp;ensure everything works as\u0026nbsp;expected\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#adding-transformation\"\u003eAdding transformation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#check-the-final-result\"\u003eCheck the final result\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#wrap-up\"\u003eWrap up\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"intro\"\u003e\u003ca href=\"#intro\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eIntro\u003c/span\u003e\u003c/a\u003eIntro\u003c/h2\u003e\n\u003cp\u003eWelcome to\u0026nbsp;this series of\u0026nbsp;posts exploring a\u0026nbsp;real-time analytics use case. The series covers various aspects of\u0026nbsp;setting up\u0026nbsp;a\u0026nbsp;real-time analytics platform using DoubleCloud managed services, from data ingestion to\u0026nbsp;aggregation computation, and finally, to\u0026nbsp;dashboards based on\u0026nbsp;those data marts.\u003c/p\u003e\n\u003cp\u003eThis first post focuses on\u0026nbsp;the initial setup and data loading using ClickHouse, Apache Kafka, and DoubleCloud\u0026rsquo;s Data Transfer.\u003c/p\u003e\n\u003ch2 id=\"data-solution-overview\"\u003e\u003ca href=\"#data-solution-overview\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eData Solution overview\u003c/span\u003e\u003c/a\u003eData Solution overview\u003c/h2\u003e\n\u003cp\u003eBy\u0026nbsp;the end of\u0026nbsp;the series, we\u0026nbsp;will have built a\u0026nbsp;setup that enables us\u0026nbsp;to\u0026nbsp;ingest and make decisions based on\u0026nbsp;clickstream data. The overall architecture of\u0026nbsp;our data platform looks like this schematically:\u003c/p\u003e\n\n\u003cp\u003eIn\u0026nbsp;the diagram, the white part represents an\u0026nbsp;external data provider (such as\u0026nbsp;a\u0026nbsp;web performance monitoring tool), while everything else consists of\u0026nbsp;DoubleCloud managed services. We\u0026nbsp;will use a\u0026nbsp;simple Python script to\u0026nbsp;send data. This first part focuses on\u0026nbsp;data ingestion, the initial setup of\u0026nbsp;our Kafka server, and the data loading process for ClickHouse:\u003c/p\u003e\n\n\u003cp\u003eThe upcoming parts of\u0026nbsp;the series will focus on\u0026nbsp;aggregations and visualization. While we\u0026nbsp;will address performance when relevant, the primary goal of\u0026nbsp;the series is\u0026nbsp;to\u0026nbsp;describe connecting the various components together.\u003c/p\u003e\n\u003ch2 id=\"problem-outline\"\u003e\u003ca href=\"#problem-outline\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eProblem outline\u003c/span\u003e\u003c/a\u003eProblem outline\u003c/h2\u003e\n\u003cp\u003eOne of\u0026nbsp;the common tasks in\u0026nbsp;real-time analytics is\u0026nbsp;performing aggregations. We\u0026nbsp;have clickstream data and want to\u0026nbsp;visualize some basic metrics related to\u0026nbsp;user activity on\u0026nbsp;the website. In\u0026nbsp;this example, which will be\u0026nbsp;used throughout the entire series, we\u0026nbsp;will use a\u0026nbsp;subset of\u0026nbsp;fields from our clickstream data to\u0026nbsp;calculate how many products were purchased during specific hours of\u0026nbsp;the day.\u003c/p\u003e\n\u003ch2 id=\"sample-event\"\u003e\u003ca href=\"#sample-event\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eSample event\u003c/span\u003e\u003c/a\u003eSample event\u003c/h2\u003e\n\u003cp\u003eHere\u0026rsquo;s an\u0026nbsp;example event from our data source, representing user interactions with products in\u0026nbsp;a\u0026nbsp;marketplace. This event is\u0026nbsp;already enriched with additional information about the user and the item they interacted with:\u003c/p\u003e\n\n    \u003cdiv class=\"yfm-clipboard\"\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs json\"\u003e\u003cspan class=\"hljs-punctuation\"\u003e{\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"basket_price\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"detectedCorruption\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003e\u003cspan class=\"hljs-keyword\"\u003efalse\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"detectedDuplicate\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003e\u003cspan class=\"hljs-keyword\"\u003efalse\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"eventType\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"itemViewEvent\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"firstInSession\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003e\u003cspan class=\"hljs-keyword\"\u003etrue\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"item_id\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"bx_VHZvTOyk_CYNTZGlxyopNGYodgtybLKqToopjOqbT\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"item_price\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e4876\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"item_url\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"https://mu3bxs.webshop24.eu/katalog/item/t-shirt-female-temptation/\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"location\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"https://mu3bxs.webshop24.eu/\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"pageViewId\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"0:qawVTkAI:IyqIWWkimHqgvBGCbeMMIoosmXiuLcvW\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"partyId\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"0:ckQoIhoa:PtdjtCnxGtRzfXvovHcDtltPSaDzpvxM\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"referer\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"https://mu3bxs.webshop24.eu//katalog/item/slippers-pink-paradise/\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"remoteHost\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"test0\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"sessionId\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"0:ZSMAmydy:yqxDDTWQfbRtrauPYAAIGQsCVubHrdov\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"timestamp\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e1545127200000\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003e\"userAgentName\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36\"\u003c/span\u003e\n\u003cspan class=\"hljs-punctuation\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\n    \u003csvg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" class=\"yfm-clipboard-button\" data-animation=\"15\"\u003e\n        \u003cpath fill=\"currentColor\" d=\"M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z\"\u003e\u003c/path\u003e\n        \u003cpath stroke=\"currentColor\" fill=\"transparent\" stroke-width=\"1.5\" d=\"M9.5 13l3 3l5 -5\" visibility=\"hidden\"\u003e\n            \u003canimate id=\"visibileAnimation-15\" attributeName=\"visibility\" from=\"hidden\" to=\"visible\" dur=\"0.2s\" fill=\"freeze\" begin\u003e\u003c/animate\u003e\n            \u003canimate id=\"hideAnimation-15\" attributeName=\"visibility\" from=\"visible\" to=\"hidden\" dur=\"1s\" begin=\"visibileAnimation-15.end+1\" fill=\"freeze\"\u003e\u003c/animate\u003e\n        \u003c/path\u003e\n    \u003c/svg\u003e\n    \u003c/div\u003e\n\u003cp\u003eFor the purpose of\u0026nbsp;our example pipeline, we\u0026nbsp;will concentrate on\u0026nbsp;a\u0026nbsp;subset of\u0026nbsp;the event\u0026rsquo;s fields and set our ingestion pipeline to\u0026nbsp;use only the ones we\u0026rsquo;re interested\u0026nbsp;in. To\u0026nbsp;compute aggregated statistics, we\u0026nbsp;will need the following fields:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003epartyId\u003c/code\u003e (string key, denoting global userId)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003esessionId\u003c/code\u003e (string key, used to\u0026nbsp;mark the same user session)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eitem_price\u003c/code\u003e (integer representing the price of\u0026nbsp;an\u0026nbsp;item)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eeventType\u003c/code\u003e (string field for the type of\u0026nbsp;event)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003edetectedDuplicate\u003c/code\u003e and \u003ccode\u003edetectedCorruption\u003c/code\u003e (boolean fields from upcoming data enrichment systems that will be\u0026nbsp;used to\u0026nbsp;filter data)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEverything else is\u0026nbsp;unnecessary for our example use case, but it\u0026rsquo;s helpful to\u0026nbsp;know what those fields are in\u0026nbsp;case there is\u0026nbsp;a\u0026nbsp;need for further analysis later.\u003c/p\u003e\n\u003cp\u003eThe Python code, along with sample data and instructions on\u0026nbsp;how to\u0026nbsp;run it, can be\u0026nbsp;found \u003ca href=\"https://github.com/doublecloud/showcase-webshop-clickstream-aggregation\"\u003ein\u0026nbsp;this repository\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"setup-infrastructure\"\u003e\u003ca href=\"#setup-infrastructure\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eSetup infrastructure\u003c/span\u003e\u003c/a\u003eSetup infrastructure\u003c/h2\u003e\n\u003ch3 id=\"kafka-cluster\"\u003e\u003ca href=\"#kafka-cluster\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eKafka cluster\u003c/span\u003e\u003c/a\u003eKafka cluster\u003c/h3\u003e\n\u003cp\u003eWe\u0026nbsp;will use Kafka as\u0026nbsp;our ingestion layer. For the purposes of\u0026nbsp;this series, we\u0026nbsp;can go\u0026nbsp;with the default options: select the eu-central-1 zone and choose the smallest possible configuration. The only change I\u0026nbsp;would personally recommend is\u0026nbsp;opting for an\u0026nbsp;ARM architecture, as\u0026nbsp;it\u0026nbsp;tends to\u0026nbsp;perform slightly better, as\u0026nbsp;highlighted in\u0026nbsp;our article on\u0026nbsp;this topic: \u003ca href=\"https://double.cloud/blog/posts/2024/06/benchmarking-apache-kafka-performance-per-price/\"\u003eBenchmarking Apache Kafka: performance per price\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSimply pick a\u0026nbsp;cluster name you\u0026rsquo;re comfortable with, select a\u0026nbsp;recent Kafka version (3.5), and you\u0026rsquo;re all set!\u003c/p\u003e\n\n\u003cp\u003eProvisioning should take a\u0026nbsp;few minutes (we\u0026nbsp;can create the ClickHouse cluster in\u0026nbsp;the meantime). Once the cluster is\u0026nbsp;up\u0026nbsp;and running, let\u0026rsquo;s navigate to\u0026nbsp;cluster settings and create a\u0026nbsp;topic for our events.\u003c/p\u003e\n\u003ch4 id=\"kafka-topic-for-incoming-messages\"\u003e\u003ca href=\"#kafka-topic-for-incoming-messages\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eKafka topic for incoming messages\u003c/span\u003e\u003c/a\u003eKafka topic for incoming messages\u003c/h4\u003e\n\u003cp\u003eWe\u0026nbsp;will be\u0026nbsp;using a\u0026nbsp;standard architectural pattern of\u0026nbsp;having a\u0026nbsp;single topic per schema, meaning that each different schema of\u0026nbsp;messages will be\u0026nbsp;assigned to\u0026nbsp;a\u0026nbsp;separate topic. Therefore, we\u0026nbsp;need to\u0026nbsp;create a\u0026nbsp;topic for incoming messages, which can be\u0026nbsp;done through the same cluster control interface.\u003c/p\u003e\n\n\u003cp\u003eFor the purpose of\u0026nbsp;this tutorial, our load is\u0026nbsp;non-threatening, so\u0026nbsp;we\u0026nbsp;can use a\u0026nbsp;simple topic with just one partition and a\u0026nbsp;replication factor of\u0026nbsp;one.\u003c/p\u003e\n\u003ch4 id=\"allowlist-caveat\"\u003e\u003ca href=\"#allowlist-caveat\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eAllowList caveat\u003c/span\u003e\u003c/a\u003eAllowList caveat\u003c/h4\u003e\n\u003cp\u003eTo\u0026nbsp;simplify testing, DoubleCloud adds your IP\u0026nbsp;address to\u0026nbsp;the \u003cstrong\u003eALLOW LIST\u003c/strong\u003e in\u0026nbsp;the cluster settings. Keep this in\u0026nbsp;mind if\u0026nbsp;you frequently switch Wi-Fi networks while working from your laptop.\u003c/p\u003e\n\u003ch3 id=\"clickhouse-cluster\"\u003e\u003ca href=\"#clickhouse-cluster\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eClickHouse cluster\u003c/span\u003e\u003c/a\u003eClickHouse cluster\u003c/h3\u003e\n\u003cp\u003eFor the ClickHouse cluster, let\u0026rsquo;s select the same availability zone and opt for the smallest possible setup: 1\u0026nbsp;replica and 1\u0026nbsp;shard, resulting in\u0026nbsp;a\u0026nbsp;single ARM node with just 32\u0026nbsp;GB\u0026nbsp;of\u0026nbsp;storage. While you would typically want a\u0026nbsp;more robust configuration for production, these defaults are sufficient for our current needs. We\u0026rsquo;ll discuss scaling a\u0026nbsp;bit in\u0026nbsp;future parts of\u0026nbsp;this series.\u003c/p\u003e\n\n\u003cp\u003eChoose a\u0026nbsp;reasonable name for the cluster and select a\u0026nbsp;relevant version. The cluster creation UI\u0026nbsp;defaults to\u0026nbsp;the latest LTS version, but there\u0026rsquo;s nothing stopping us\u0026nbsp;from opting for a\u0026nbsp;more recent one.\u003c/p\u003e\n\u003ch4 id=\"clickhouse-database\"\u003e\u003ca href=\"#clickhouse-database\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eClickHouse database\u003c/span\u003e\u003c/a\u003eClickHouse database\u003c/h4\u003e\n\u003cp\u003eWhile we\u0026nbsp;can use the default database for ClickHouse, it\u0026nbsp;makes sense to\u0026nbsp;create a\u0026nbsp;different one for our application. Let\u0026rsquo;s go\u0026nbsp;ahead and do\u0026nbsp;that. There are multiple ways to\u0026nbsp;access our cluster, but the easiest method is\u0026nbsp;to\u0026nbsp;use the WebSQL interface. From the cluster interface, click on\u0026nbsp;the \u003cstrong\u003eWebSQL\u003c/strong\u003e button to\u0026nbsp;open the interface in\u0026nbsp;the new tab.\u003c/p\u003e\n\n\u003cp\u003eThis will automatically connect to\u0026nbsp;the cluster and authorize with admin credentials. Clicking on\u0026nbsp;any entity in\u0026nbsp;the left tree menu will open the query editor. Execute the following code to\u0026nbsp;create a\u0026nbsp;new database:\u003c/p\u003e\n\n    \u003cdiv class=\"yfm-clipboard\"\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs sql\"\u003e\u003cspan class=\"hljs-keyword\"\u003eCREATE\u003c/span\u003e DATABASE webshop;\n\u003c/code\u003e\u003c/pre\u003e\n\n    \u003csvg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" class=\"yfm-clipboard-button\" data-animation=\"3\"\u003e\n        \u003cpath fill=\"currentColor\" d=\"M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z\"\u003e\u003c/path\u003e\n        \u003cpath stroke=\"currentColor\" fill=\"transparent\" stroke-width=\"1.5\" d=\"M9.5 13l3 3l5 -5\" visibility=\"hidden\"\u003e\n            \u003canimate id=\"visibileAnimation-3\" attributeName=\"visibility\" from=\"hidden\" to=\"visible\" dur=\"0.2s\" fill=\"freeze\" begin\u003e\u003c/animate\u003e\n            \u003canimate id=\"hideAnimation-3\" attributeName=\"visibility\" from=\"visible\" to=\"hidden\" dur=\"1s\" begin=\"visibileAnimation-3.end+1\" fill=\"freeze\"\u003e\u003c/animate\u003e\n        \u003c/path\u003e\n    \u003c/svg\u003e\n    \u003c/div\u003e\n\n\u003cp\u003eI\u0026nbsp;suggest naming the new database \u003cstrong\u003ewebshop\u003c/strong\u003e, and I\u0026nbsp;will use this name in\u0026nbsp;the examples moving forward. Now that we\u0026nbsp;have our source and destination set up, let\u0026rsquo;s create a\u0026nbsp;\u003cstrong\u003eData Transfer\u003c/strong\u003e pipeline to\u0026nbsp;connect them.\u003c/p\u003e\n\u003ch4 id=\"allowlist-caveat\"\u003e\u003ca href=\"#allowlist-caveat\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eAllowList caveat\u003c/span\u003e\u003c/a\u003eAllowList caveat\u003c/h4\u003e\n\u003cp\u003eSimilar to\u0026nbsp;the Kafka cluster, DoubleCloud adds your IP\u0026nbsp;address to\u0026nbsp;the \u003cstrong\u003eALLOW LIST\u003c/strong\u003e in\u0026nbsp;the cluster settings behind the scenes. Keep this in\u0026nbsp;mind if\u0026nbsp;you frequently switch Wi-Fi networks while working from your laptop. It\u0026nbsp;is\u0026nbsp;advised not to\u0026nbsp;open your cluster to\u0026nbsp;the world carelessly, even for short-term testing purposes.\u003c/p\u003e\n\u003ch2 id=\"setup-transfer-endpoints\"\u003e\u003ca href=\"#setup-transfer-endpoints\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eSetup transfer endpoints\u003c/span\u003e\u003c/a\u003eSetup transfer endpoints\u003c/h2\u003e\n\u003cp\u003eDoubleCloud provides a\u0026nbsp;convenient way to\u0026nbsp;ingest data from Kafka to\u0026nbsp;ClickHouse through a\u0026nbsp;tool called \u003ca href=\"https://double.cloud/services/doublecloud-transfer/\"\u003eData Transfer\u003c/a\u003e. We\u0026nbsp;will use \u003cstrong\u003eTransfer\u003c/strong\u003e to\u0026nbsp;read data from our \u003cstrong\u003eKafka topic\u003c/strong\u003e (referred to\u0026nbsp;as\u0026nbsp;the source endpoint in\u0026nbsp;Transfer\u0026rsquo;s terminology) and publish it\u0026nbsp;to\u0026nbsp;\u003cstrong\u003eClickHouse\u003c/strong\u003e (the target endpoint in\u0026nbsp;Transfer\u0026rsquo;s terminology). Let\u0026rsquo;s set it\u0026nbsp;up!\u003c/p\u003e\n\u003ch3 id=\"kafka-transport-source-endpoint\"\u003e\u003ca href=\"#kafka-transport-source-endpoint\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eKafka: Transport source endpoint\u003c/span\u003e\u003c/a\u003eKafka: Transport source endpoint\u003c/h3\u003e\n\u003cp\u003eNavigate to\u0026nbsp;the \u003cstrong\u003eTransfer\u003c/strong\u003e page, switch to\u0026nbsp;the \u003cstrong\u003eEndpoint\u003c/strong\u003e tab, and create a\u0026nbsp;source endpoint. Select \u003cstrong\u003eKafka\u003c/strong\u003e as\u0026nbsp;the source type in\u0026nbsp;the dropdown and give it\u0026nbsp;a\u0026nbsp;reasonable name (this name will be\u0026nbsp;used internally by\u0026nbsp;Transfer).\u003c/p\u003e\n\n\u003cp\u003eSelect the recently created Kafka cluster and use the credentials to\u0026nbsp;connect to\u0026nbsp;it\u0026nbsp;via SASL. To\u0026nbsp;make the endpoint functional, add the topic that was created earlier.\u003c/p\u003e\n\u003ch4 id=\"json-fields\"\u003e\u003ca href=\"#json-fields\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eJSON fields\u003c/span\u003e\u003c/a\u003eJSON fields\u003c/h4\u003e\n\u003cp\u003eSince the initial analysis of\u0026nbsp;event data showed that we\u0026nbsp;don\u0026rsquo;t need all the fields, we\u0026nbsp;can include only the ones we\u0026nbsp;are interested\u0026nbsp;in. This can be\u0026nbsp;done using the \u003cstrong\u003eAdvanced settings\u003c/strong\u003e tab, where we\u0026nbsp;can specify a\u0026nbsp;JSON conversion rule with a\u0026nbsp;list of\u0026nbsp;relevant fields. Here\u0026rsquo;s what I\u0026nbsp;ended up\u0026nbsp;with:\u003c/p\u003e\n\n\u003cp\u003eAdditionally, since I\u0026nbsp;might be\u0026nbsp;interested in\u0026nbsp;other fields later, I\u0026rsquo;ll make sure that a\u0026nbsp;corresponding option is\u0026nbsp;enabled, just in\u0026nbsp;case.\u003c/p\u003e\n\u003ch3 id=\"clickhouse-transport-target-endpoint\"\u003e\u003ca href=\"#clickhouse-transport-target-endpoint\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eClickHouse: Transport target endpoint\u003c/span\u003e\u003c/a\u003eClickHouse: Transport target endpoint\u003c/h3\u003e\n\u003cp\u003eCreating the target endpoint is\u0026nbsp;straightforward as\u0026nbsp;well. There\u0026rsquo;s no\u0026nbsp;need for any additional setup; simply select the connection type, choose the correct cluster from the dropdown menu, and specify the target database (schema).\u003c/p\u003e\n\n\u003cp\u003eNow that both endpoints are set up, we\u0026nbsp;need to\u0026nbsp;create the transfer itself.\u003c/p\u003e\n\u003ch2 id=\"creating-and-activating-the-transfer\"\u003e\u003ca href=\"#creating-and-activating-the-transfer\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eCreating and activating the Transfer\u003c/span\u003e\u003c/a\u003eCreating and activating the Transfer\u003c/h2\u003e\n\u003cp\u003eWe\u0026nbsp;need to\u0026nbsp;specify the created endpoints, choose a\u0026nbsp;name, and that\u0026rsquo;s\u0026nbsp;it. Everything else can be\u0026nbsp;left at\u0026nbsp;the default settings. Click \u003cstrong\u003e\u0026ldquo;Submit\u0026rdquo;\u003c/strong\u003e and grab a\u0026nbsp;cup of\u0026nbsp;tea while the transfer is\u0026nbsp;being created.\u003c/p\u003e\n\n\u003cp\u003eOnce the transfer is\u0026nbsp;created, we\u0026nbsp;need to\u0026nbsp;activate it\u0026nbsp;and ensure it\u0026nbsp;is\u0026nbsp;running (its status should change accordingly).\u003c/p\u003e\n\n\u003ch2 id=\"producer-script\"\u003e\u003ca href=\"#producer-script\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eProducer script\u003c/span\u003e\u003c/a\u003eProducer script\u003c/h2\u003e\n\u003cp\u003eTo\u0026nbsp;test the pipeline, we\u0026nbsp;will be\u0026nbsp;producing 1,000 events from a\u0026nbsp;file using a\u0026nbsp;Python script. \u003ca href=\"https://github.com/doublecloud/showcase-webshop-clickstream-aggregation\"\u003eYou can check the source here\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eTo\u0026nbsp;run the script, install the required packages, set the environment variables for cluster access, and execute the following command in\u0026nbsp;the terminal:\u003c/p\u003e\n\n    \u003cdiv class=\"yfm-clipboard\"\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs python\"\u003eclickstream/produce_events.py\n\u003c/code\u003e\u003c/pre\u003e\n\n    \u003csvg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" class=\"yfm-clipboard-button\" data-animation=\"9\"\u003e\n        \u003cpath fill=\"currentColor\" d=\"M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z\"\u003e\u003c/path\u003e\n        \u003cpath stroke=\"currentColor\" fill=\"transparent\" stroke-width=\"1.5\" d=\"M9.5 13l3 3l5 -5\" visibility=\"hidden\"\u003e\n            \u003canimate id=\"visibileAnimation-9\" attributeName=\"visibility\" from=\"hidden\" to=\"visible\" dur=\"0.2s\" fill=\"freeze\" begin\u003e\u003c/animate\u003e\n            \u003canimate id=\"hideAnimation-9\" attributeName=\"visibility\" from=\"visible\" to=\"hidden\" dur=\"1s\" begin=\"visibileAnimation-9.end+1\" fill=\"freeze\"\u003e\u003c/animate\u003e\n        \u003c/path\u003e\n    \u003c/svg\u003e\n    \u003c/div\u003e\n\u003cp\u003eThis will produce 1,000 events from the file \u003cstrong\u003eevents1000.jsonl\u003c/strong\u003e. Refer to\u0026nbsp;the \u003ccode\u003eREADME\u003c/code\u003e if\u0026nbsp;you want to\u0026nbsp;customize something, encounter any issues or\u0026nbsp;if\u0026nbsp;you want to\u0026nbsp;manipulate the data first, such as\u0026nbsp;moving it\u0026nbsp;in\u0026nbsp;time if\u0026nbsp;needed.\u003c/p\u003e\n\u003ch2 id=\"sanity-checks-to-ensure-everything-works-as-expected\"\u003e\u003ca href=\"#sanity-checks-to-ensure-everything-works-as-expected\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eSanity checks to\u0026nbsp;ensure everything works as\u0026nbsp;expected\u003c/span\u003e\u003c/a\u003eSanity checks to\u0026nbsp;ensure everything works as\u0026nbsp;expected\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s perform some queries from the WebSQL interface to\u0026nbsp;check our data. If\u0026nbsp;we\u0026nbsp;open WebSQL Query editor, we\u0026nbsp;can see that all 1,000 events have arrived:\u003c/p\u003e\n\n\u003cp\u003eThe next logical step is\u0026nbsp;to\u0026nbsp;verify that the timestamps are in\u0026nbsp;the expected format:\u003c/p\u003e\n\n\u003cp\u003eIt\u0026nbsp;appears that the dates are slightly too futuristic. A\u0026nbsp;common issue with numeric timestamps from different systems is\u0026nbsp;that they might use different time formats. For example, one system might use microseconds while another uses seconds. Let\u0026rsquo;s see if\u0026nbsp;dividing the timestamp resolves the issue:\u003c/p\u003e\n\n\u003cp\u003eAnd indeed, it\u0026nbsp;does! We\u0026nbsp;now have two options:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAccount for the fact that our timestamps need special treatment before proceeding with the analysis.\u003c/li\u003e\n\u003cli\u003eTransform the timestamps upon ingestion.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTypical data modeling approach is\u0026nbsp;to\u0026nbsp;choose the first option, where you don\u0026rsquo;t modify data at\u0026nbsp;the ingestion \u003cstrong\u003e\u0026ldquo;source\u0026rdquo;\u003c/strong\u003e level and instead perform preparation in\u0026nbsp;the next stage.\u003c/p\u003e\n\u003cp\u003eHowever, in\u0026nbsp;modern data pipelines, it\u0026nbsp;is\u0026nbsp;generally acceptable to\u0026nbsp;perform simple transformations during ingestion, as\u0026nbsp;long as\u0026nbsp;they are indeed straightforward. Thankfully, Transfer is\u0026nbsp;capable of\u0026nbsp;doing just that!\u003c/p\u003e\n\u003ch2 id=\"adding-transformation\"\u003e\u003ca href=\"#adding-transformation\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eAdding transformation\u003c/span\u003e\u003c/a\u003eAdding transformation\u003c/h2\u003e\n\u003cp\u003eIf\u0026nbsp;we\u0026nbsp;go\u0026nbsp;back to\u0026nbsp;our transfer and open \u003cstrong\u003eEdit\u003c/strong\u003e view, we\u0026rsquo;ll find a\u0026nbsp;button labeled \u003cstrong\u003e\u0026ldquo;Transformation\u0026rdquo;\u003c/strong\u003e towards the end of\u0026nbsp;the page:\u003c/p\u003e\n\n\u003cp\u003eThis humble little feature is\u0026nbsp;exactly what we\u0026nbsp;need for our transformation. Transfer supports multiple ways to\u0026nbsp;adjust your data as\u0026nbsp;it\u0026nbsp;moves between endpoints. We\u0026nbsp;will use the on-the-fly SQL processor. Click on\u0026nbsp;the button and select \u003cstrong\u003e\u0026ldquo;SQL\u0026rdquo;\u003c/strong\u003e from the Transformer dropdown. I\u0026rsquo;ll create a\u0026nbsp;new field called \u003cstrong\u003e\u0026ldquo;my_ts\u0026rdquo;\u003c/strong\u003e that will hold the original timestamp divided by\u0026nbsp;1,000:\u003c/p\u003e\n\n\u003cp\u003eBy\u0026nbsp;the way, Transfer allows you to\u0026nbsp;stack multiple transformations in\u0026nbsp;a\u0026nbsp;chain of\u0026nbsp;operations if\u0026nbsp;you wish. However, there are some limitations to\u0026nbsp;what is\u0026nbsp;possible and, more importantly, what should be\u0026nbsp;done at\u0026nbsp;this step. Keep in\u0026nbsp;mind that these operations are effectively hidden from your view, so\u0026nbsp;you should avoid extensive data transformations here and instead leave that to\u0026nbsp;your ETL processes in\u0026nbsp;the next stage of\u0026nbsp;the data processing pipeline.\u003c/p\u003e\n\u003ch2 id=\"check-the-final-result\"\u003e\u003ca href=\"#check-the-final-result\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eCheck the final result\u003c/span\u003e\u003c/a\u003eCheck the final result\u003c/h2\u003e\n\u003cp\u003eUpdate the transfer, drop the table (since we\u0026nbsp;are altering the scheme, this is\u0026nbsp;the easiest way to\u0026nbsp;update it), produce new data, and voil\u0026agrave;! We\u0026nbsp;have our timestamp in\u0026nbsp;expected format and within the correct century.\u003c/p\u003e\n\n\u003ch2 id=\"wrap-up\"\u003e\u003ca href=\"#wrap-up\" class=\"yfm-anchor\" aria-hidden=\"true\"\u003e\u003cspan class=\"visually-hidden\"\u003eWrap up\u003c/span\u003e\u003c/a\u003eWrap up\u003c/h2\u003e\n\u003cp\u003eIn\u0026nbsp;just a\u0026nbsp;few clicks, we\u0026nbsp;have created a\u0026nbsp;Kafka cluster, a\u0026nbsp;ClickHouse cluster, and a\u0026nbsp;Transfer pipeline with on-the-fly data transformation that now ingests incoming data in\u0026nbsp;our database. We\u0026nbsp;have everything ready to\u0026nbsp;start computing aggregates, which we\u0026nbsp;will cover in\u0026nbsp;the next part. Stay tuned for Part II!\u003c/p\u003e\n\u003cp\u003eIf\u0026nbsp;you have any questions or\u0026nbsp;would like to\u0026nbsp;discuss this series further, feel free to\u0026nbsp;\u003ca href=\"https://join.slack.com/t/double-cloud/shared_invite/zt-1pbz9lfte-5GoIX~8CmVYqmVQfRFPNdA\"\u003ereach out on\u0026nbsp;Slack\u003c/a\u003e.\u003c/p\u003e\n","sharing":{"title":"Clickstream analytics case study. Part I: Kafka -\u003e Data Transfer -\u003e ClickHouse","description":"How to set up a real-time analytics pipeline using Kafka and ClickHouse: initial setup and data loading.","image":"/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-sharing.png","shareGenImage":"","shareGenTitle":"Clickstream analytics case study. Part I: Kafka -\u003e Data Transfer -\u003e ClickHouse"},"keywords":[],"noIndex":false,"authors":[],"tags":[{"icon":null,"slug":"insights","name":"Insights","createdAt":"","updatedAt":"","count":0},{"icon":null,"slug":"ClickHouse","name":"ClickHouse","createdAt":"","updatedAt":"","count":0},{"icon":null,"slug":"kafka","name":"Kafka","createdAt":"","updatedAt":"","count":0}],"metaSchema":{"@context":"https://schema.org","@graph":[{"@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"insights","name":"Insights"}},{"@type":"ListItem","position":2,"item":{"@id":"ClickHouse","name":"ClickHouse"}},{"@type":"ListItem","position":3,"item":{"@id":"kafka","name":"Kafka"}}]},{"@type":"BlogPosting","@id":"https://double.cloud/blog/posts/2024/09/real-time-analytics-kafka-clickhouse-integration/","url":"https://double.cloud/blog/posts/2024/09/real-time-analytics-kafka-clickhouse-integration/","name":"Clickstream analytics case study. Part I: Kafka → Data Transfer → ClickHouse","headline":"Clickstream analytics case study. Part I: Kafka → Data Transfer → ClickHouse","abstract":"\u003cp\u003eWritten By: Igor Mosyagin, Developer Advocate at\u0026nbsp;DoubleCloud\u003c/p\u003e","description":"\u003cp\u003eWritten By: Igor Mosyagin, Developer Advocate at\u0026nbsp;DoubleCloud\u003c/p\u003e","dateCreated":"2024-09-06T00:00:00Z","datePublished":"2024-09-06T00:00:00Z","dateModified":"2024-09-06T00:00:00Z","author":{"@type":"Organization","name":"DoubleCloud","legalName":"DoubleCloud Inc","url":"https://double.cloud/","logo":{"@type":"ImageObject","url":"","width":32,"height":32}},"creator":{"@type":"Organization","name":"DoubleCloud","legalName":"DoubleCloud Inc","url":"https://double.cloud/","logo":{"@type":"ImageObject","url":"","width":32,"height":32}},"publisher":{"@type":"Organization","name":"DoubleCloud","legalName":"DoubleCloud Inc","url":"https://double.cloud/","logo":{"@type":"ImageObject","url":"","width":32,"height":32}},"copyrightHolder":{"@type":"Organization","name":"DoubleCloud","legalName":"DoubleCloud Inc","url":"https://double.cloud/","logo":{"@type":"ImageObject","url":"","width":32,"height":32}},"copyrightYear":2025,"mainEntityOfPage":{"@type":"WebPage","@id":"https://double.cloud/blog/posts/2024/09/real-time-analytics-kafka-clickhouse-integration/"},"inLanguage":{"@type":"Language","name":"English","alternateName":"en"},"keywords":["Insights","ClickHouse","Kafka"],"image":"https://double.cloud/assets/blog/articles/2024/real-time-analytics-kafka-clickhouse-integration-small-cover.png","sharedContent":{"@type":"WebPage","headline":"Clickstream analytics case study. Part I: Kafka → Data Transfer → ClickHouse","url":"https://double.cloud/blog/posts/2024/09/real-time-analytics-kafka-clickhouse-integration/","author":{"@type":"Organization","name":"DoubleCloud","legalName":"DoubleCloud Inc","url":"https://double.cloud/","logo":{"@type":"ImageObject","url":"","width":32,"height":32}}},"wordCount":"","articleBody":""}]}},"routingData":{"hostname":"double.cloud"},"deviceData":{"isRobot":true,"isMobile":false,"isTablet":false},"csrfToken":"CafYsR4H-JVXjNMxUs4Q_KIJk9N8jFVEgj-4","clientConfig":{"appTitle":"DoubleCloud","legalName":"DoubleCloud Inc","supportEmail":"","hosts":{"site":"https://double.cloud","console":"https://app.double.cloud"}},"ignoreConsent":false,"noNextImg":false,"noSnippet":null},"__N_SSP":true},"page":"/blog/posts/[...slug]","query":{"slug":["2024","09","real-time-analytics-kafka-clickhouse-integration"]},"buildId":"HkxA3M0ES7gp3V0n_0ecw","isFallback":false,"gssp":true,"locale":"en","locales":["en"],"defaultLocale":"en","scriptLoader":[]}</script></body></html>